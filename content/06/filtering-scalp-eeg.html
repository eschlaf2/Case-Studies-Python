<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>Case Studies in Neural Data Analysis</title>
  <meta name="description" content=" # Application of Filtering to Scalp EEG Data+++    _**Synopsis**_ **Data:** Ten 1 s trials of EEG data sampled at 1000 Hz.**Goal:** Filter these data to ide...">

  <link rel="canonical" href="https://mark-kramer.github.io/Case-Studies-Python/content/06/filtering-scalp-eeg.html">
  <link rel="alternate" type="application/rss+xml" title="Case Studies in Neural Data Analysis" href="https://mark-kramer.github.io/Case-Studies-Python/feed.xml">

  <meta property="og:url"         content="https://mark-kramer.github.io/Case-Studies-Python/content/06/filtering-scalp-eeg.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Case Studies in Neural Data Analysis" />
<meta property="og:description" content=" # Application of Filtering to Scalp EEG Data+++    _**Synopsis**_ **Data:** Ten 1 s trials of EEG data sampled at 1000 Hz.**Goal:** Filter these data to ide..." />
<meta property="og:image"       content="https://mark-kramer.github.io/Case-Studies-Python/images/logo/logo.png" />

<meta name="twitter:card" content="summary">


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage": "https://mark-kramer.github.io/Case-Studies-Python/content/06/filtering-scalp-eeg.html",
  "headline": "Case Studies in Neural Data Analysis",
  "datePublished": "2020-06-12T15:51:41-04:00",
  "dateModified": "2020-06-12T15:51:41-04:00",
  "description": " # Application of Filtering to Scalp EEG Data+++    _**Synopsis**_ **Data:** Ten 1 s trials of EEG data sampled at 1000 Hz.**Goal:** Filter these data to ide...",
  "author": {
    "@type": "Person",
    "name": "Mark Kramer and Uri Eden"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "https://mark-kramer.github.io/Case-Studies-Python",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "https://mark-kramer.github.io/Case-Studies-Python",
    "height": 60,
    "width": 60
  }
}

  </script>
  <link rel="stylesheet" href="/Case-Studies-Python/assets/css/styles.css">

  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="/Case-Studies-Python/images/logo/favicon.ico">

  <!-- MathJax Config -->
  <!-- Allow inline math using $ and automatically break long math lines -->
<!-- (mostly) copied from nbconvert configuration -->
<!-- https://github.com/jupyter/nbconvert/blob/master/nbconvert/templates/html/mathjax.tpl -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true
    },
    // Center justify equations in code and markdown cells. Elsewhere
    // we use CSS to left justify single line equations in code cells.
    displayAlign: 'center',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}},
        linebreaks: { automatic: true },
    },
    
});
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML' async></script>


  <!-- DOM updating function -->
  <script src="/Case-Studies-Python/assets/js/page/dom-update.js"></script>

  <!-- Selectors for elements on the page -->
  <script src="/Case-Studies-Python/assets/js/page/documentSelectors.js"></script>

  <!-- Define some javascript variables that will be useful in other javascript -->
  <script>
    const site_basename = '/Case-Studies-Python';
  </script>

  <!-- Add AnchorJS to let headers be linked -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js" async></script>
  <script src="/Case-Studies-Python/assets/js/page/anchors.js" async></script>

  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/turbolinks/5.2.0/turbolinks.js" async></script>
  <meta name="turbolinks-cache-control" content="no-cache">

  <!-- Load nbinteract for widgets -->
  

  <!-- Load Thebelab for interactive widgets -->
  <!-- Include Thebelab for interactive code if it's enabled -->


<!-- Display Thebelab button in each code cell -->
<script>
/**
 * Set up thebelab button for code blocks
 */

const thebelabCellButton = id =>
  `<a id="thebelab-cell-button-${id}" class="btn thebebtn o-tooltip--left" data-tooltip="Interactive Mode">
    <img src="/Case-Studies-Python/assets/images/edit-button.svg" alt="Start thebelab interactive mode">
  </a>`


const addThebelabButtonToCodeCells =  () => {

  const codeCells = document.querySelectorAll('div.input_area > div.highlight:not(.output) pre')
  codeCells.forEach((codeCell, index) => {
    const id = codeCellId(index)
    codeCell.setAttribute('id', id)
    if (document.getElementById("thebelab-cell-button-" + id) == null) {
      codeCell.insertAdjacentHTML('afterend', thebelabCellButton(id));
    }
  })
}

initFunction(addThebelabButtonToCodeCells);
</script>


<script src="https://unpkg.com/thebelab@latest/lib/index.js" async></script>
<script>
    /**
     * Add attributes to Thebelab blocks
     */

    const initThebelab = () => {
        const addThebelabToCodeCells = () => {
            console.log("Adding thebelab to code cells...");
            // If Thebelab hasn't loaded, wait a bit and try again. This
            // happens because we load ClipboardJS asynchronously.
            if (window.thebelab === undefined) {
                setTimeout(addThebelabToCodeCells, 250)
            return
            }

            // If we already detect a Thebelab cell, don't re-run
            if (document.querySelectorAll('div.thebelab-cell').length > 0) {
                return;
            }

            // Find all code cells, replace with Thebelab interactive code cells
            const codeCells = document.querySelectorAll('.input_area pre')
            codeCells.forEach((codeCell, index) => {
                const id = codeCellId(index)

                // Clean up the language to make it work w/ CodeMirror and add it to the cell
                dataLanguage = ""
                dataLanguage = detectLanguage(dataLanguage);
                codeCell.setAttribute('data-language', dataLanguage)
                codeCell.setAttribute('data-executable', 'true')

                // If the code cell is hidden, show it
                var inputCheckbox = document.querySelector(`input#hidebtn${codeCell.id}`);
                if (inputCheckbox !== null) {
                    setCodeCellVisibility(inputCheckbox, 'visible');
                }
            });

            // Remove the event listener from the page so keyboard press doesn't
            // Change page
            document.removeEventListener('keydown', initPageNav)
            keyboardListener = false;

            // Init thebelab
            thebelab.bootstrap();

            // Remove copy buttons since they won't work anymore
            const copyAndThebeButtons = document.querySelectorAll('.copybtn, .thebebtn')
            copyAndThebeButtons.forEach((button, index) => {
                button.remove();
            });

            // Remove outputs since they'll be stale
            const outputs = document.querySelectorAll('.output *, .output')
            outputs.forEach((output, index) => {
                output.remove();
            });

            // Find any cells with an initialization tag and ask ThebeLab to run them when ready
            var thebeInitCells = document.querySelectorAll('div.tag_thebelab-init');
            thebeInitCells.forEach((cell) => {
                console.log("Initializing ThebeLab with cell: " + cell.id);
                cell.querySelector('.thebelab-run-button').click();
            });
        }

        // Add event listener for the function to modify code cells
        const thebelabButtons = document.querySelectorAll('[id^=thebelab], [id$=thebelab]')
        thebelabButtons.forEach((thebelabButton,index) => {
            if (thebelabButton === null) {
                setTimeout(initThebelab, 250)
                return
            };
            thebelabButton.addEventListener('click', addThebelabToCodeCells);
        });
    }

    // Initialize Thebelab
    initFunction(initThebelab);

// Helper function to munge the language name
var detectLanguage = (language) => {
    if (language.indexOf('python') > -1) {
        language = "python";
    }
    return language;
}
</script>



  <!-- Load the auto-generating TOC (non-async otherwise the TOC won't load w/ turbolinks) -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.8.1/tocbot.min.js" async></script>
  <script src="/Case-Studies-Python/assets/js/page/tocbot.js"></script>

  <!-- Google analytics -->
  


  <!-- Clipboard copy button -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script>

  <!-- Load custom website scripts -->
  <script src="/Case-Studies-Python/assets/js/scripts.js" async></script>

  <!-- Load custom user CSS and JS  -->
  <script src="/Case-Studies-Python/assets/custom/custom.js" async></script>
  <link rel="stylesheet" href="/Case-Studies-Python/assets/custom/custom.css">

  <!-- Update interact links w/ REST param, is defined in includes so we can use templates -->
  
<script>
/**
  * To auto-embed hub URLs in interact links if given in a RESTful fashion
 */

function getJsonFromUrl(url) {
  var query = url.split('?');
  if (query.length < 2) {
    // No queries so just return false
    return false;
  }
  query = query[1];
  // Collect REST params into a dictionary
  var result = {};
  query.split("&").forEach(function(part) {
    var item = part.split("=");
    result[item[0]] = decodeURIComponent(item[1]);
  });
  return result;
}
    
function dict2param(dict) {
    params = Object.keys(dict).map(function(k) {
        return encodeURIComponent(k) + '=' + encodeURIComponent(dict[k])
    });
    return params.join('&')
}

// Parse a Binder URL, converting it to the string needed for JupyterHub
function binder2Jupyterhub(url) {
  newUrl = {};
  parts = url.split('v2/gh/')[1];
  // Grab the base repo information
  repoinfo = parts.split('?')[0];
  var [org, repo, ref] = repoinfo.split('/');
  newUrl['repo'] = ['https://github.com', org, repo].join('/');
  newUrl['branch'] = ref
  // Grab extra parameters passed
  params = getJsonFromUrl(url);
  if (params['filepath'] !== undefined) {
    newUrl['subPath'] = params['filepath']
  }
  return dict2param(newUrl);
}

// Filter out potentially unsafe characters to prevent xss
function safeUrl(url)
{
   return String(encodeURIComponent(url))
            .replace(/&/g, '&amp;')
            .replace(/"/g, '&quot;')
            .replace(/'/g, '&#39;')
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;');
}

function addParamToInternalLinks(hub) {
  var links = document.querySelectorAll("a").forEach(function(link) {
    var href = link.href;
    // If the link is an internal link...
    if (href.search("https://mark-kramer.github.io") !== -1 || href.startsWith('/') || href.search("127.0.0.1:") !== -1) {
      // Assume we're an internal link, add the hub param to it
      var params = getJsonFromUrl(href);
      if (params !== false) {
        // We have REST params, so append a new one
        params['jupyterhub'] = hub;
      } else {
        // Create the REST params
        params = {'jupyterhub': hub};
      }
      // Update the link
      var newHref = href.split('?')[0] + '?' + dict2param(params);
      link.setAttribute('href', decodeURIComponent(newHref));
    }
  });
  return false;
}


// Update interact links
function updateInteractLink() {
    // hack to make this work since it expects a ? in the URL
    rest = getJsonFromUrl("?" + location.search.substr(1));
    jupyterHubUrl = rest['jupyterhub'];
    var hubType = null;
    var hubUrl = null;
    if (jupyterHubUrl !== undefined) {
      hubType = 'jupyterhub';
      hubUrl = jupyterHubUrl;
    }

    if (hubType !== null) {
      // Sanitize the hubUrl
      hubUrl = safeUrl(hubUrl);

      // Add HTTP text if omitted
      if (hubUrl.indexOf('http') < 0) {hubUrl = 'http://' + hubUrl;}
      var interactButtons = document.querySelectorAll("button.interact-button")
      var lastButton = interactButtons[interactButtons.length-1];
      var link = lastButton.parentElement;

      // If we've already run this, skip the link updating
      if (link.nextElementSibling !== null) {
        return;
      }

      // Update the link and add context div
      var href = link.getAttribute('href');
      if (lastButton.id === 'interact-button-binder') {
        // If binder links exist, we need to re-work them for jupyterhub
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // If localhost, assume we're working from a local Jupyter server and remove `/hub`
          first = [hubUrl, 'git-sync'].join('/')
        } else {
          first = [hubUrl, 'hub', 'user-redirect', 'git-sync'].join('/')
        }
        href = first + '?' + binder2Jupyterhub(href);
      } else {
        // If interact button isn't binderhub, assume it's jupyterhub
        // If JupyterHub links, we only need to replace the hub url
        href = href.replace("", hubUrl);
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // Assume we're working from a local Jupyter server and remove `/hub`
          href = href.replace("/hub/user-redirect", "");
        }
      }
      link.setAttribute('href', decodeURIComponent(href));

      // Add text after interact link saying where we're launching
      hubUrlNoHttp = decodeURIComponent(hubUrl).replace('http://', '').replace('https://', '');
      link.insertAdjacentHTML('afterend', '<div class="interact-context">on ' + hubUrlNoHttp + '</div>');

      // Update internal links so we retain the hub url
      addParamToInternalLinks(hubUrl);
    }
}

runWhenDOMLoaded(updateInteractLink)
document.addEventListener('turbolinks:load', updateInteractLink)
</script>


  <!-- Lunr search code - will only be executed on the /search page -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.6/lunr.min.js" async></script>
  <script>var initQuery = function() {
  // See if we have a search box
  var searchInput = document.querySelector('input#lunr_search');
  if (searchInput === null) {
    return;
  }

  // Function to parse our lunr cache
  var idx = lunr(function () {
    this.field('title')
    this.field('excerpt')
    this.field('categories')
    this.field('tags')
    this.ref('id')

    this.pipeline.remove(lunr.trimmer)

    for (var item in store) {
      this.add({
        title: store[item].title,
        excerpt: store[item].excerpt,
        categories: store[item].categories,
        tags: store[item].tags,
        id: item
      })
    }
  });

  // Run search upon keyup
  searchInput.addEventListener('keyup', function () {
    var resultdiv = document.querySelector('#results');
    var query = document.querySelector("input#lunr_search").value.toLowerCase();
    var result =
      idx.query(function (q) {
        query.split(lunr.tokenizer.separator).forEach(function (term) {
          q.term(term, { boost: 100 })
          if(query.lastIndexOf(" ") != query.length-1){
            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })
          }
          if (term != ""){
            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })
          }
        })
      });

      // Empty the results div
      while (resultdiv.firstChild) {
        resultdiv.removeChild(resultdiv.firstChild);
      }

    resultdiv.insertAdjacentHTML('afterbegin', '<p class="results__found">'+result.length+' Result(s) found</p>');
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].teaser){
        var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<div class="archive__item-teaser">'+
                '<img src="'+store[ref].teaser+'" alt="">'+
              '</div>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      else{
    	  var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      resultdiv.insertAdjacentHTML('beforeend', searchitem);
    }
  });
};

initFunction(initQuery);
</script>

  <!-- Load JS that depends on site variables -->
  <script src="/Case-Studies-Python/assets/js/page/copy-button.js" async></script>

  <!-- Hide cell code -->
  <script src="/Case-Studies-Python/assets/js/page/hide-cell.js" async></script>

  <!-- Printing the screen -->
  <!-- Include nbinteract for interactive widgets -->
<script src="https://printjs-4de6.kxcdn.com/print.min.js" async></script>
<script>
printContent = () => {
    // MathJax displays a second version of any math for assistive devices etc.
    // This prevents double-rendering in the PDF output.
    var ignoreAssistList = [];
    assistives = document.querySelectorAll('.MathJax_Display span.MJX_Assistive_MathML').forEach((element, index) => {
        var thisId = 'MathJax-assistive-' + index.toString();
        element.setAttribute('id', thisId);
        ignoreAssistList.push(thisId)
    });

    // Print the actual content object
    printJS({
        printable: 'textbook_content',
        type: 'html',
        css: "/Case-Studies-Python/assets/css/styles.css",
        style: "#textbook_content {padding-top: 40px};",
        scanStyles: false,
        targetStyles: ["*"],
        ignoreElements: ignoreAssistList,
        documentTitle: "Made with Jupyter Book"
    })
};

initPrint = () => {
    document.querySelector('#interact-button-print').addEventListener('click', printContent)
}

initFunction(initPrint)
</script>

</head>

  <body>
    <!-- Include the ThebeLab config so it gets reloaded on each page -->
    <script type="text/x-thebe-config">{
    requestKernel: true,
    binderOptions: {
    repo: "mark-kramer/Case-Studies-Python",
    ref: "master",
    },
    codeMirrorConfig: {
    theme: "abcdef",
    mode: "python"
    },
    kernelOptions: {
    kernelName: "python3",
    path: ""
    }
}
</script>

    <!-- .js-show-sidebar shows sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      



<nav id="js-sidebar" class="c-textbook__sidebar">
  <a href="https://mitpress.mit.edu/books/case-studies-neural-data-analysis" target="_blank" rel="noopener noreferrer"><img src="/Case-Studies-Python/images/logo/logo.png" class="textbook_logo" id="sidebar-logo" alt="textbook logo" data-turbolinks-permanent></a>
  <h2 class="c-sidebar__title">Case Studies in Neural Data Analysis</h2>
  <ul class="c-sidebar__chapters">
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/intro">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/intro.html">
          
          Home
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      
        <li class="c-sidebar__divider">
        
      
      
        <li><h2 class="c-sidebar__title">Contents</h2></li>
        
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/01/introduction-to-python">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/01/introduction-to-python.html">
          
            1.
          
          Introduction to Python
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/02/the-event-related-potential">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/02/the-event-related-potential.html">
          
            2.
          
          The Event-Related Potential
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/03/the-power-spectrum-part-1">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/03/the-power-spectrum-part-1.html">
          
            3.
          
          The Power Spectrum (Part 1)
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/04/ecog-rhythms">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/04/ecog-rhythms.html">
          
            4.
          
          The Power Spectrum (Part 2)
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/05/the-cross-covariance-and-coherence">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/05/the-cross-covariance-and-coherence.html">
          
            5.
          
          The Cross Covariance and Coherence
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/06/filtering-scalp-eeg">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/06/filtering-scalp-eeg.html">
          
            6.
          
          Filtering Field Data
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/07/cross-frequency-coupling">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/07/cross-frequency-coupling.html">
          
            7.
          
          Cross Frequency Coupling
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/08/basic-visualizations-and-descriptive-statistics-of-spike-train-data">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/08/basic-visualizations-and-descriptive-statistics-of-spike-train-data.html">
          
            8.
          
          Basic Visualizations and Descriptive Statistics of Spike Train Data
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/09/point-process-glms">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/09/point-process-glms.html">
          
            9.
          
          Modeling place Fields with Point Process Generalized Linear Models
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/10/spiking-rhythms">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/10/spiking-rhythms.html">
          
            10.
          
          Analysis of Rhythmic Spiking in the Subthalamic Nucleus During a Movement Task
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/11/spike-field-coherence">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/11/spike-field-coherence.html">
          
            11.
          
          Analysis of Spike-Field Coherence
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      
        <li class="c-sidebar__divider">
        
      
      
        <li><h2 class="c-sidebar__title">Appendices</h2></li>
        
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/A01/backprop">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/A01/backprop.html">
          
            12.
          
          Backpropagation
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/A02/HH">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/A02/HH.html">
          
            13.
          
          Hodgkin Huxley Model
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/A03/LIF">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/A03/LIF.html">
          
            14.
          
          Integrate and Fire Model
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/A04/perceptron">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/A04/perceptron.html">
          
            15.
          
          Training a Perceptron
        </a>
      </li>

      
      

      

      
      

      

      
    
  </ul>
  <p class="sidebar_footer">Powered by <a href="https://github.com/jupyter/jupyter-book" target="_blank" rel="noopener noreferrer">Jupyter Book</a></p>
</nav>

      
      <div class="c-topbar" id="top-navbar">
  <!-- We show the sidebar by default so we use .is-active -->
  <div class="c-topbar__buttons">
    <button id="js-sidebar-toggle" class="hamburger hamburger--arrowalt is-active">
      <span class="hamburger-box">
        <span class="hamburger-inner"></span>
      </span>
    </button>
    <div class="buttons">
<div class="download-buttons-dropdown">
    <button id="dropdown-button-trigger" class="interact-button"><img src="/Case-Studies-Python/assets/images/download-solid.svg" alt="Download"></button>
    <div class="download-buttons">
        
        <a id="interact-button-print"><button id="interact-button-download" class="interact-button">.pdf</button></a>
    </div>
</div>


</div>

  </div>
  <!-- Empty sidebar placeholder that we'll auto-fill with javascript -->
  <aside class="sidebar__right">
    <header><h4 class="nav__title">
<img src="/Case-Studies-Python/assets/images/list-solid.svg" alt="Search">   On this page</h4></header>
    <nav class="onthispage">
    </nav>
  </aside>
  <a href="/Case-Studies-Python/search.html" class="topbar-right-button" id="search-button">
    <img src="/Case-Studies-Python/assets/images/search-solid.svg" alt="Search">
  </a>
</div>

      <main class="c-textbook__page" tabindex="-1">
            <div class="c-textbook__content" id="textbook_content">
              <p><a id="top"></a></p>
<h1 id="application-of-filtering-to-scalp-eeg-data">Application of Filtering to Scalp EEG Data</h1>

<p>+++</p>

<div class="question">

  <p><em><strong>Synopsis</strong></em></p>

  <p><strong>Data:</strong> Ten 1 s trials of EEG data sampled at 1000 Hz.</p>

  <p><strong>Goal:</strong> Filter these data to identify an evoked response.</p>

  <p><strong>Tools:</strong> Fourier transform, convolution, magnitude response, frequency response, phase response.</p>

</div>

<p>+++</p>

<ul>
  <li><a href="#.">Introduction</a></li>
  <li>
<a href="#data-analysis">Data analysis</a>
    <ol>
      <li><a href="#visual-inspection">Visual inspection</a></li>
      <li><a href="#spectral-analysis">Spectrial Analysis</a></li>
      <li><a href="#evoked-response">Evoked Response and Average Spectrum</a></li>
      <li><a href="#naive-filters">Naive Filtering</a></li>
      <li><a href="#advanced-filters">More Sophisticated Filtering</a></li>
      <li><a href="#phase">What’s Phase Got to Do with It?</a></li>
      <li><a href="#analysis">Analysis of the Filtered EEG Data</a></li>
    </ol>
  </li>
  <li><a href="#summary">Summary</a></li>
</ul>

<p>+++</p>

<h2 id="on-ramp-filtering-field-data-in-python">On-ramp: filtering field data in Python</h2>
<p>We begin this module with an “<em>on-ramp</em>” to analysis. The purpose of this on-ramp is to introduce you immediately to a core concept in this module: how to filter field data in Python. You may not understand all aspects of the program here, but that’s not the point. Instead, the purpose of this on-ramp is to illustrate what <em>can</em> be done. Our advice is to simply run the code below and see what happens …</p>

<p>```{code-cell} ipython3
import numpy as np
from numpy.fft import fft, ifft, rfft, fftfreq
from scipy.signal import firwin, lfilter, filtfilt
from scipy.io import loadmat
import matplotlib.pyplot as plt
from matplotlib.pyplot import *
%matplotlib inline</p>

<p>data = loadmat(‘EEG-1.mat’)    # Load the data,
eeg = data[‘EEG’]              # … and define the EEG,
t = data[‘t’][0]               # … and a time axis.</p>

<p>dt = t[1] - t[0]               # Define the sampling interval.
fNQ = 1 / dt / 2               # Determine the Nyquist frequency.
K = len(eeg)                   # Determine no. of trials.</p>

<p>n = 100                        # Define the filter order
Wn = 30 / fNQ                  # … and specify the cutoff frequency,
b = firwin(n, Wn)              # … build lowpass FIR filter,
                               # … and zero-phase filter each trial
eeg_lo = np.array([filtfilt(b, 1, eeg[k]) for k in range(K)])</p>

<p>mn = eeg_lo.mean(0)            # Compute mean of filtered EEG across trials (ERP)
sd = eeg_lo.std(0)             # Compute std of filtered EEG data across trials.
sdmn = sd / np.sqrt(K);        # Compute the std of the mean.</p>

<p>plot(t, mn)                    # Plot the ERP of the filtered data
plot(t, mn + 2 * sdmn, ‘r:’);  # … and the confidence intervals,
plot(t, mn - 2 * sdmn, ‘r:’);
xlabel(‘Time [s]’)             # … and label the axes.
ylabel(‘Voltage [ mV]’)
title(‘Evoked response of filtered EEG’)
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;div class="question"&gt;
    
**Q:** Try to read the code above. Can you see how it loads data, lowpass filters it, and then plots the ERP of the filtered data?

**A:** If you've never created and applied a filter before, that's an especially difficult question. Please continue on to learn this **and more**!

&lt;/div&gt;

+++

## Introduction
In previous case studies, we analyzed brain rhythms and discussed techniques to characterize these rhythms. Observed brain rhythms are often corrupted by noise. Sometimes this noise is obvious (e.g., electrical noise). In general, however, identifying the components of a brain signal that constitute signal versus noise is a difficult problem.

In this module, we develop techniques to isolate, emphasize, or remove rhythmic activity in neural field data. To do so we introduce a broad area of study and research: **filtering**. In general, filtering is a very common procedure in the analysis of neural data. Although it is typically considered a preprocessing step, how filtering is performed may make or break subsequent analysis. This is a vast area, and we focus here on only some of the important concepts and tools.

### Case study data
Our colleague recorded the electroencephalogram (EEG) from a human subject during a task. After performing the experiment, he analyzed the data with the hope of finding an evoked response over visual cortex. However, his initial analysis suggested no evoked response. He therefore asked us to assist in his data analysis. He provided us with the EEG data recorded on the scalp surface above the left occipital lobe of one subject. He would like to understand the rhythmic features that appear in these data during the recording, and in particular whether an evoked response can be detected. He provided us with ten trials of EEG data, each of duration 1 s, recorded during the subject’s response to a visual stimulus (a small flash of light).

### Goals
Our goal is to better understand whether an evoked response appears in the data. We first make a visual inspection of the data, using techniques we developed to [study evoked responses](../02). However, our main goal is to understand the fundamental procedures of filtering neural field data, and we examine filtering methods applied to these example EEG data. We start by developing an intuitive approach to filtering and then implement and apply more sophisticated methods. We explain procedures to visualize filter properties and the resulting impact on the input signal.

### Tools
In this chapter, we rely on the Fourier transform (and associated measures) to develop a basic understanding of filters. If you are not confident using the Fourier transform, we strongly recommend reviewing modules [3](../03) and [4](../04). This case study reinforces concepts in those modules and provides another opportunity to compute and to examine spectra, and to examine the relationships between the time and frequency domain representations of a time series. Upon completing this module, you should be familiar with basic filtering principles and methods to visualize the impact of filters, and equipped for further study and development of filtering procedures.

```{code-cell} ipython3
import numpy as np
from numpy import hanning, angle
from numpy.fft import fft, ifft, rfft, fftfreq
from scipy.signal import firwin, lfilter, filtfilt
from scipy.io import loadmat
import matplotlib.pyplot as plt
from matplotlib.pyplot import *
%matplotlib inline
</code></pre></div></div>

<h2 id="data-analysis">Data analysis<a id="data-analysis"></a>
</h2>

<p>As always, let’s begin by looking at the data. To do so, we load the EEG data into Python and plot it:
<a id="fig:1"></a></p>

<p>```{code-cell} ipython3
data = loadmat(‘EEG-1.mat’)  # Load the EEG data
eeg = data[‘EEG’]            # Extract the EEG variable
t = data[‘t’][0]             # … and the t variable</p>

<p>rcParams[‘figure.figsize’] = (12, 3)  # Default to wide figures
plot(t, eeg[0])              # Plot the data from the first trial versus time
xlabel(‘Time [s]’)           # Label the time axis
ylabel(‘Voltage [mV]’)       # … and the voltage axis
savefig(‘imgs/6-1.png’)
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
We note that the variable `eeg` is a matrix, with each row corresponding to a single trial. Inspection of the variable `eeg` reveals there are 10 trials (i.e., 10 rows) each consisting of 1,000 indices. We also note that the visual stimulus is delivered just after the start of the trial (at time 0.001 s, corresponding to index 0 of variable `t`), and the response is recorded for the subsequent 1 s (the time 1 s corresponds to index 999 of variable `t`).

+++

&lt;div class="question"&gt;
    
**Q.** What are the sampling interval and sampling frequency of the EEG data?
    
**A.** Inspection of the variable `t`, loaded into Python, reveals that the sampling interval is 0.001 s, or 1 ms, and the sampling frequency is therefore 1/(0.001 s), or 1000 Hz.
    
&lt;/div&gt;

+++

Visual inspection of the 1 s interval of the first trial suggests at least two distinct features. First, a rapid oscillation appears to occur, with amplitude near 1 mV. Second, a large deviation in voltage occurs (near 0.2 s). Additional slower oscillations may occur, although it’s difficult to tell from visual inspection alone.

+++

&lt;div class="question"&gt;
    
**Q.** Consider the fast rhythmic activity that dominates the EEG data plotted above. What is the frequency of this dominant rhythm? Do you observe an evoked response in this single trial? If so, where in time, and what features characterize the evoked response?
    
**A.** Careful counting of the number of peaks (or troughs) in the signal reveals that the fast rhythmic activity has a frequency of approximately 60 Hz. Visual inspection of the single-trial data does not suggest an evoked response (at least to the authors).
    
&lt;/div&gt;

+++

&lt;div class="question"&gt;

**Q.** Examine other individual trials of the EEG data. Do you find features similar to those in the first trial?

&lt;/div&gt;

+++

[Back to top](#top)

+++

### Spectral Analysis&lt;a id="spectral-analysis"&gt;&lt;/a&gt;

Initial visual inspection of the single-trial data suggests that a 60 Hz rhythm dominates each individual trial. To further characterize this observation, let’s compute the spectrum of a single trial of EEG data &lt;sup&gt;&lt;abbr title="We could instead write the sample spectrum because this equation uses the observed data to estimate the theoretical spectrum that we would see if we kept repeating this experiment, but this distinction is not essential to the discussion here."&gt;note&lt;/abbr&gt;&lt;/sup&gt;. We do so here for the first trial, and apply a Hanning taper before computing the spectrum (see [chapter 4](../04)):
&lt;a id="fig:2"&gt;&lt;/a&gt;

```{code-cell} ipython3
x = eeg[0]                # Load the first trial.
x = x - x.mean()          # Subtract the mean from the data.
dt = t[1] - t[0]          # Define the sampling interval.
T = t[-1]                 # Define the duration of the trial.
N = len(x)                # Define the number of points in the trial.

xh = hanning(N) * x       # Multiply data by Hanning window,
xf = rfft(xh)[:-1]        # ... compute Fourier transform,
Sxx = 2 * dt ** 2 / T * (xf * xf.conj());  #... and compute spectrum.

df = 1 / T;               # Determine frequency resolution.
fNQ = 1 / dt / 2;         # Determine Nyquist frequency.
faxis = np.arange(0, fNQ, df)              # Construct frequency axis

semilogx(faxis, 10 * np.log10(Sxx.real))   # Plot decibels vs frequency,
xlim([df, 100])           # ... in limited frequency range,
xlabel('Frequency [Hz]')  # ... with axes labeled.
ylabel('Power [dB]')
title('Single-trial spectrum')
savefig('imgs/6-2')
show()
</code></pre></div></div>

<p>Notice that in the second line of code, we remove the mean from the single trial of data. This is not always necessary but often useful; we are usually most interested in the rhythmic behavior of the EEG activity, not the changes in the mean signal.</p>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> What is the resulting frequency resolution?</p>

  <p><strong>A.</strong> The total duration of a trial is 1 s. Therefore the frequency resolution is 1/(1 s) = 1 Hz. If this answer makes no sense, we recommend reviewing the case study in <a href="../03">chapter 3</a>.</p>

</div>

<p>+++</p>

<p>The resulting spectrum reveals two important features. First, the power spectral density appears increased at lower frequencies compared to higher frequencies, that is, the spectrum tends to decrease with increasing frequency. This distribution of power is common in neural field data (e.g., <a href="https://doi.org/10.1016/j.neuron.2010.04.020" target="_blank" rel="noopener noreferrer">[He, et al., 2010]</a>) and in other biological systems <a href="https://doi.org/10.1103/PhysRevLett.59.381" target="_blank" rel="noopener noreferrer">[Bak, Tang, &amp; Wiesenfeld, 1987]</a>. Second, a large peak occurs at 60 Hz. This peak is consistent with the dominant rhythm apparent through visual inspection of the data in the first trial<a href="#fig:1" class="sup">fig<span><img src="imgs/6-1.png"></span></a>.</p>

<p>A 60 Hz peak is common in EEG data recorded in North America, where the alternating current in an electrical socket has frequency 60 Hz. We might also perhaps observe a second small peak between approximately 15 and 25 Hz. However, it’s not immediately apparent whether this peak represents a rhythm or a random fluctuation in the (noisy) spectrum. In any case, these initial spectral results are somewhat reassuring. The data exhibit characteristics we expect in typical scalp EEG data. Namely, the spectrum tends to decrease with frequency, and a large, sharp 60 Hz peak occurs, consistent with electrical noise.</p>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> Examine the spectrum of other individual trials. Do you find features similar to those in trial 1?</p>

</div>

<p>+++</p>

<p><a href="#top">Back to Top</a></p>
<h3 id="evoked-response-and-the-average-spectrum">Evoked Response and the Average Spectrum<a id="evoked-response"></a>
</h3>

<p>Initial inspection of the features observable in the individual trials of EEG data has not been encouraging; the data appear to be dominated by 60 Hz line noise, with an occasional large-amplitude deviation. Through this initial inspection, it’s not clear whether an evoked response occurs in these data. We may therefore conclude that if an evoked response does occur in the data, the effect is weak and not apparent in a single trial. To further search for a weak evoked effect, let’s average the EEG responses across trials. In doing so, we hope that events unrelated to the stimulus will be reduced while responses evoked by the stimulus will be enhanced (see <a href="../02">chapter 2</a>). More specifically, let’s compute the mean and standard deviation of the mean EEG response at each time across trials:
<a id="fig:3"></a></p>

<p>```{code-cell} ipython3
K = len(eeg)                   # Define variable to record no. of trials
mn = eeg.mean(0)               # Compute mean EEG across trials (ERP)
sd = eeg.std(0)                # Compute std of EEG data across trials.
sdmn = sd / np.sqrt(K);        # Compute the std of the mean.</p>

<p>plot(t, mn)                    # Plot the ERP,
plot(t, mn + 2 * sdmn, ‘r:’);  # … and the confidence intervals,
plot(t, mn - 2 * sdmn, ‘r:’);
xlabel(‘Time [s]’)             # … and label the axes.
ylabel(‘Voltage [ mV]’)
title(‘Evoked response’)
savefig(‘imgs/6-3a.png’)
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Visual inspection suggests three important features. First, the 60 Hz rhythm, which dominated the individual trial data, is less prominent here. Second, large and brief increases in voltage appear in the ERP throughout the 1 s interval (e.g., at times near 0.2 s and at times near 0.8 s). Third, an interesting event appears near time 0.5 s, where we observe a brief interval of rhythmic fluctuations. The mean voltage appears to increase and decrease approximately twice in 125 ms, corresponding to an approximate 16 Hz rhythm. These mean results suggest an evoked response near time 0.5 s. However, we also observe that the 95% confidence intervals of the ERP include zero; we therefore do not find evidence for a significant ERP.

In addition to the ERP, we also compute the trial-averaged spectrum: 
&lt;a id="fig:3b"&gt;&lt;/a&gt;

```{code-cell} ipython3
def spectrum(x, t, hann=True):
    '''
    Define a function that computes the power spectrum 
    for any given x (trial data) and t (time of samples).
    '''
    dt = t[1] - t[0]
    T  = t[-1]
    x  = x - x.mean()
    xh = hanning(N) * x if hann else x
    xf = rfft(xh)[:-1]
    Sxx = 2 * dt ** 2 / T * (xf * xf.conj())
    return Sxx.real

Sxx = [spectrum(trial, t, False) for trial in eeg] # Compute the spectrum for each trial.
Sxxmn = np.array(Sxx).mean(0)                      # Convert the result into an array and compute the mean.
semilogx(faxis, 10 * np.log10(Sxxmn))              # Plot the result in decibels vs frequency,
xlim([df, 100])                                    # ... in limited frequency range,
ylim([-40,0])                                      # ... and limited power range,
xlabel('Frequency [Hz]')                           # ... with axes labeled.
ylabel('Power [dB]')
title('Trial averaged spectrum')
savefig('imgs/6-3b.png')
show()
</code></pre></div></div>

<p>Compared to the <a href="fig:2" class="fig">single-trial spectrum<span><img src="imgs/6-2.png"></span></a>, the variability is greatly reduced in the <a href="fig:3b" class="fig">trial-averaged spectrum<span><img src="imgs/6-3b.png"></span></a>. By reducing the variability in this way, the rhythmic peak between 15 Hz and 25 Hz becomes more apparent. We also observe both the 60 Hz electrical noise peak and the trend of decreasing power spectral density with increasing frequency, as in the single-trial spectrum.</p>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> Given the initial analysis, what conclusions do you make regarding the EEG data?</p>

  <p><strong>A.</strong> The analysis of the single-trial and trial-averaged results suggests that 60 Hz electrical noise dominates the EEG signal. We observe this electrical noise directly in the voltage traces and as a prominent sharp peak in the spectrum. We have some suggestive observations that an interesting evoked response may occur in the data but no conclusive (i.e., significant) evidence. Perhaps if we can reduce the 60 Hz electrical noise, we can uncover a weak evoked response that is currently hidden by the 60 Hz signal. To reduce the 60 Hz signal, we next try to filter these data.</p>

</div>

<p>+++</p>

<p><a href="#top">Back to Top</a></p>
<h3 id="naive-filtering">Naive Filtering<a id="naive-filters"></a>
</h3>

<p>In this section, we introduce some fundamental concepts related to filtering. An easy approach to filtering is simply to use packaged Python functions to implement standard filtering methods. However, this approach can be dangerous. If we treat the filter as a black box, then we may not understand what a filter actually does and when it might fail to perform as we hope. To gain intuition for filtering, we therefore begin with a naive approach. This approach uses understanding of the Fourier transform and spectrum, and allows us to investigate how a simple filter performs. We then attempt to improve this naive approach, again using notions familiar from the study of spectra in previous chapters (see chapters <a href="../03">3</a> and <a href="../04">4</a>). Through this approach we do not implement the most sophisticated or useful filters; in fact, we do not recommend using this approach in practice. But we develop a deeper understanding of what a filter actually does. Later, we use packaged functions to implement standard filtering approaches. Ideally, these built-in functions will seem more interpretable with the knowledge gained through the initial naive filtering investigations.</p>

<h4 id="a-naive-rectangular-filter">A Naive Rectangular Filter.</h4>

<p>Initial analysis of the data suggests that the dominant rhythmic activity is 60 Hz electrical noise. This activity is reassuring (we expect it) but also a nuisance; because the line noise is so dominant, other interesting features of lower amplitude may be masked. To search further for a weak evoked response in the data, we must reduce the dominant 60 Hz rhythm.</p>

<p>We build our own filter to achieve this goal. The idea is simple: eliminate the 60 Hz rhythm from the EEG data. Recall that the Fourier transform converts a time domain representation of a signal to a frequency domain representation. Schematically, in symbols,</p>

<p><a id="eq:1"></a>
<script type="math/tex">x_n \xrightarrow{\text{FT}} X_j \tag{1}</script></p>

<p>where $x_n$ is the data at each time index $n$, $X_j$ is the data at each frequency index $j$, and $FT$ denotes the Fourier transform. We also note that the inverse Fourier transform ($iFT$) converts the frequency domain representation of the data back to the time domain:</p>

<p><a id="eq:2"></a>
<script type="math/tex">x_n \xleftarrow{\text{iFT}} X_j \tag{2}</script></p>

<p>With these concepts, we may define three steps for a naive rectangular filter:</p>

<ol>
  <li>Move the observed EEG data to the frequency domain by computing the Fourier transform.</li>
  <li>Set the frequency domain components of the EEG signal at 60 Hz to zero.</li>
  <li>Move the altered data back to the time domain by computing the inverse Fourier transform.</li>
</ol>

<p>We call this initial approach a naive rectangular filter. We call it “naive” because we’re using naive intuition to construct the filter; we propose to eliminate the 60 Hz activity in the frequency domain in the simplest way and explore the consequences. We call it “rectangular” because we isolate abrupt intervals in the frequency domain to eliminate. Let’s attempt this procedure and examine the impact on the EEG data.</p>

<h5 id="step-1">Step 1.</h5>
<p>Our first step is to compute the Fourier transform of the EEG data. We focus specifically on the first trial; the same analysis can be performed on any individual trial. For completeness, we recompute some quantities from the previous sections:</p>

<p>```{code-cell} ipython3
x = eeg[0]        # Relabel the data from trial 1,
x = x - x.mean()  # … subtract the mean from the data, 
xf = fft(x)       # … and compute the FT</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;div class="question"&gt;

**Q.** What are the dimensions of `xf`?

**A.** Note that `xf` is a vector with the same dimensions as the original EEG data from trial 1 (labeled `x`). Remember that computing the Fourier transform of a signal does not alter its dimensions. However, also note that `xf` is a complex vector, consisting of both real and imaginary parts.

&lt;/div&gt;

+++

##### Step 2.

We first define the frequency axis that corresponds to `xf`. We do so in the standard way implemented in previous chapters:

```{code-cell} ipython3
dt = t[1] - t[0]        # Define the sampling interval.
N = len(x)              # Define the number of points in a single trial.
faxis = fftfreq(N, dt)  # Construct the frequency axis
</code></pre></div></div>

<p>Here we use the function <code class="language-plaintext highlighter-rouge">fftfreq()</code>, which first lists the positive frequencies, and then the
negative frequencies. The construction is simimlar to traversing a circle whos angles are in the range of [$-\pi$, $\pi$]. If you start at zero, and rotate in a positive direction, you will eventually jump from $\pi$ to $-\pi$, and then continue. Let’s visualize <code class="language-plaintext highlighter-rouge">faxis</code> computed with this function:</p>

<p>```{code-cell} ipython3
plot(faxis)
ylabel(‘Frequency (Hz)’)
xlabel(‘Index’)
title(‘Frequency axis’)
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Notice that the frequency axis (`faxis`) consists of both positive and negative frequencies. When examining the spectrum, we typically ignore the redundant negative frequencies. However, when developing a filter, we must be careful to include all frequencies. The frequency domain representation of the EEG data requires both positive and negative frequencies, and we must adjust both to filter the signal. Also notice that we use `fftfreq()` to easily compute the frequency axis.

+++

&lt;div class="question"&gt;
    
**Q.** Consider the real and imaginary components of xf as a function of frequency. For each component, is the negative frequency axis a redundant representation of the positive frequency axis? *Hint*: Consider a plot of the imaginary component of `xf` versus frequency:

    plot(faxis, xf.imag)

What do you observe?

&lt;/div&gt;

+++

With the frequency axis defined, let’s now identify the indices corresponding to the 60 Hz rhythm we’d like to remove from the signal. Of the many approaches to perform this search, here’s one:

```{code-cell} ipython3
# Find interval near 60 Hz.
indices = (abs(faxis) &gt;= 59) &amp; (abs(faxis) &lt;= 61)
</code></pre></div></div>

<p>In words, we find the indices where the absolute value of the frequency is between 59 and 61 (i.e., within 1 Hz of the target frequency, 60 Hz).</p>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> Confirm that the values of <code class="language-plaintext highlighter-rouge">faxis</code> at the determined indices are less than, or equal to, 1 Hz from ±60 Hz.</p>

  <p><strong>A.</strong> Executing the command:</p>

  <div class="language-plaintext highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>faxis[indices]
</code></pre></div>  </div>

  <p>we find two intervals of values: (-61, -60, -59) Hz, and (59, 60, 61) Hz, consistent with our expectations.</p>

</div>

<p>+++</p>

<p>With the indices surrounding the line noise frequency located, we’re ready to set the frequency domain components of the EEG signal at 60 Hz to zero. Let’s first define the filter in the frequency domain. This filter will have a value of 1 at all frequencies except near ±60 Hz, where we set the filter to 0. We then apply this filter to the frequency domain representation of the EEG data. By doing so, we set the (complex) values of <code class="language-plaintext highlighter-rouge">xf</code> (i.e., the frequency domain representation of the EEG data) to zero at the indices surrounding the line noise frequency. At all other indices, we leave <code class="language-plaintext highlighter-rouge">xf</code> unaltered (i.e., we multiply by 1).</p>

<p>```{code-cell} ipython3
rectangular_filter = np.ones_like(x)   # Define filter in frequency domain
rectangular_filter[indices] = 0        # … set the filter at line-noise frequencies to zero
xf_filtered = xf * rectangular_filter  # … apply filter to data</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Before continuing, let’s visualize the filter and anticipate the impact on the frequency domain representation of the EEG data. We plot the variable `rectangular_filter`, the real part of `xf`, and their element-by-element product versus frequency.
&lt;a id="fig:4"&gt;&lt;/a&gt;

```{code-cell} ipython3
isorted = np.argsort(faxis)                       # Sort the frequency axis
plot(faxis[isorted], rectangular_filter[isorted]) # Plot rectangular filter vs frequency
xlabel('Freq (Hz)')                               # ... with axes labeled
ylabel('Naive square filter')
title('Naive filter in frequency domain')
xlim([-80, 80])
savefig('imgs/6-4.png')
show()
</code></pre></div></div>

<p>```{code-cell} ipython3
plot(faxis[isorted], xf.real[isorted], label=”xf”) # Plot real part of xf
                                                   # … and real part of xf after filtering
plot(faxis[isorted], xf_filtered.real[isorted], label=’xf filtered’)
xlabel(‘Freq (Hz)’)                                # … with axes labeled
ylabel(‘Real(xf)’)
title(‘Impact of naive filter on xf’)
xlim([-80, 80])
legend()
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;div class="python-note"&gt;

Recall that `faxis` starts with the positive frequencies and then jumps to the negative frequencies. To display clearly the plots requires an additional step:

    isorted = np.argsort(faxis)
    
where `isorted` are the indices that sort the frequency axis in ascending order. In the code above we use these indices to plot `rectangular_filter`, `xf` and `xf_filtered` according to the sorted values of `faxis`.

&lt;/div&gt;

+++

We find that the filter maintains a value of 1 at all frequencies except for small intervals near &amp;plusmn;60 Hz, where the filter has a value of 0. Considering the frequency domain representation of the EEG data, we observe that the real part of `xf` exhibits large peaks at &amp;plusmn;60 Hz; these peaks correspond to the dominant 60 Hz rhythm apparent in the time domain EEG data. To apply the filter, we multiply the filter by the frequency domain representation of the data at each frequency. The result is shown in orange above. The peaks at &amp;plusmn;60 Hz are eliminated because the value of the filter is set to 0 near these frequencies. All other frequency components in the EEG data are preserved, unaltered by the filter. The frequency domain representation of the EEG data also consists of an imaginary component, which we did not plot. However, the filter is applied to both the real and imaginary parts of `xf` through the element-by-element multiplication that defines `xf_filtered`.

+++

##### Step 3.

Having eliminated the line noise in the frequency domain, we’re now ready to perform the third step of the naive rectangular filter. We apply the inverse Fourier transform, and transform the manipulated frequency domain signal back to the time domain:

```{code-cell} ipython3
xnew = ifft(xf_filtered)        # Compute iFT of freq domain data.
</code></pre></div></div>

<div class="question">

  <p><strong>Q.</strong> If the procedure behaves as expected, the resulting time domain signal <code class="language-plaintext highlighter-rouge">xnew</code> should be real and contain no imaginary components, consistent with the original EEG data. Is this so?</p>

  <p><strong>A.</strong> To verify this, consider the command</p>

  <div class="language-plaintext highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>max(xnew.imag)
</code></pre></div>  </div>

  <p>You should find a value equal to (or within numerical precision of) zero.</p>

</div>

<p>+++</p>

<p>To understand the behavior of the new filtered signal in the time domain, let’s plot it. 
<a id="fig:5a"></a></p>

<p>```{code-cell} ipython3
xnew = xnew.real                # The imag components are within numerical precision of 0.</p>

<p>fig, ax = subplots()            # Save the resulting plots for later use
plot(t, x, label=’x’)           # Plot the original signal
ax.plot(t, xnew, label=’xnew’)  # … and the filtered signal
xlabel(‘Time (s)’)              # … with axes labeled
ylabel(‘Voltage (mV)’)
fig.legend()
savefig(‘imgs/6-5a.png’)
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
An initial visual inspection suggests that the filter has the desired effect; the 60 Hz line noise is dramatically reduced. The same is true in the frequency domain. 
&lt;a id="fig:5b"&gt;&lt;/a&gt;

```{code-cell} ipython3
# Compute and plot the spectrum of the unfiltered signal.
plot(np.arange(0, fNQ, df), 10 * np.log10(spectrum(x, t)), label='xf')
# Compute and plot the spectrum of the filtered signal.
plot(np.arange(0, fNQ, df), 10 * np.log10(spectrum(xnew.real, t)), label='xf_filtered')
xlim([0, 100])
xlabel('Freq (Hz)')
ylabel('Power (dB)')
legend()
savefig('imgs/6-5b.png')
show()
</code></pre></div></div>

<p>The spectrum of the original signal matches the spectrum of the filtered signal at all frequencies except near 60 Hz, where the power spectral density of the filtered signal is dramatically reduced.</p>

<p>These initial observations suggest that the naive filter is performing quite well and achieving its intended purpose. Yet something is amiss. Consider an expanded view of the filtered signal near the large, brief increase in voltage at t ≈ 0.2 s.
<a id="fig:5c"></a></p>

<p>```{code-cell} ipython3
ax.lines.pop(0)         # Hide the plot of x
ax.set_ylim([-.2, .5])  # Zoom in on the y-axis
savefig(‘imgs/6-5c.png’)
fig</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;div class="question"&gt;
    
**Q.** Do any features stand out in the plot above? Consider the voltage fluctuations near the large, brief increase in voltage in the filtered EEG data. What do you observe?

**A.** Careful visual inspection suggests that near the abrupt voltage increase, small-amplitude oscillations emerge in the filtered signal. These oscillations appear to persist for an extended time interval around the abrupt amplitude deviation (at least 100 ms before and after the deviation) and have a period near 60 Hz.

&lt;/div&gt;

+++

We might interpret the small-amplitude, approximately 60 Hz transient rhythms surrounding each large-amplitude deviation in the EEG data as a biological phenomenon. Perhaps the brain generates these coupled dynamics (i.e., the spike and surrounding rhythmic activity) to achieve a particular function. If so, this would be an important scientific result. However, let’s maintain some skepticism regarding the initial filter we’ve developed. Perhaps our filtering procedure is producing these small-amplitude rhythms around each spike; if so, these rhythms are an artifact of our analysis, not a biologically generated phenomenon. In what follows, we continue to explore the impact of the initial filter and suggest ways to further test the naive rectangular filter’s performance.

#### Impulse response.

So far we’ve characterized the naive rectangular filter by its impact in the frequency domain. To further characterize this filter, we examine its behavior in the time domain by computing the *impulse response*. As the name suggests, the impulse response indicates the filter’s response to a simple input signal consisting of a single brief impulse. The impulse, although simple in the time domain, possesses spectral content across a wide frequency range; it takes many sinusoids to represent a sharp object like an impulse. In this way, the impulse probes how the filter behaves to input with rich spectral content. We implement the impulse response as follows:
&lt;a id="fig:6a"&gt;&lt;/a&gt;

```{code-cell} ipython3
impulse = np.zeros_like(rectangular_filter)  # Define the input signal,
impulse[N // 2] = 1                          # ... with an impulse at the midpoint.
impulsef = fft(impulse) * rectangular_filter # Apply naive filter,
impulse_response = ifft(impulsef).real       # ... and iFT back to time domain
lag_axis = np.arange(-N // 2, N // 2) * dt   # Define lag axis,

fig, ax = subplots()                         # ... and plot the results.
ax.plot(lag_axis, impulse_response, label="impulse response")
ax.plot(lag_axis, impulse, label="impulse")
xlabel('Time (s)')
ylabel('Impulse response')
legend()
savefig('imgs/6-6a.png')
show()
</code></pre></div></div>

<p>Above, we see the original impulse and the impulse response (i.e., the result of applying the naive rectangular filter to the impulse). Visual inspection suggests how the filter affects the input signal in the time domain; we see that the filtered impulse consists of a large peak (centered at the time of the original impulse). By focusing on a small vertical range, we find that the peak at time 0 s is surrounded by smaller-amplitude fluctuations. 
<a id="fig:6b"></a></p>

<p>```{code-cell} ipython3
ax.set_ylim([-.01, .01])
savefig(‘imgs/6-6b.png’)
fig</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Although these fluctuations are small, we notice that they persist across all time indices examined. By focusing both the vertical and horizontal range, we observe that these fluctuations are periodic, with a period of 60 Hz.

```{code-cell} ipython3
ax.set_xlim([-.1, .1])
savefig('imgs/6-6c.png')
fig
</code></pre></div></div>

<p>The impulse response provides important insights into the behavior of the naive rectangular filter: an impulse occurring in the original signal impacts all time points in the resulting filtered signal through small-amplitude 60 Hz fluctuations.</p>

<p>We are concerned about this impulse response for the naive rectangular filter. We find that an impulse, initially localized to a single index in time, becomes broadly distributed in time upon filtering. To further illustrate the impact of the naive rectangular filter, let’s consider a more direct method to apply a filter and compute the impulse response. Up to this point, we applied the filter by first transforming the input signal to the frequency domain, then performing an element-by-element multiplication of the input signal and filter, and finally transforming the result back to the time domain. We can avoid these transformations by remembering the following important fact.</p>

<p>+++</p>

<div class="question">

  <p><strong>Multiplication in the frequency domain is equivalent to convolution in the time domain.</strong></p>

</div>

<p>+++</p>

<p>Therefore, as an alternative method for computing the impulse response, we convolve the impulse with the time domain representation of the filter. By doing so, we no longer need to transform to and from the frequency domain.</p>

<p>```{code-cell} ipython3
i_rectangular_filter = ifft(rectangular_filter).real  # Transform the filter to the time domain,
impulse_response_t = np.zeros_like(t)                 # … and define the impulse response,
for ii in range(N):                                   # … at each time point
    inds = [(ii - n) % N for n in range(N)]           # … by computing the convolution
    impulse_response_t[ii] = (i_rectangular_filter[inds] * impulse).sum()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Notice that in this code we compute the convolution by hand. We do so to make explicit the computation performed. At each time index (`ii`), we multiply element by element the shifted rectangular filter in the time domain (note the definition of `inds`) by the impulse. At each shift, we sum the elements of this product; the result is the impulse response at time index `ii`. Conceptually, we may visualize the convolution as multiplying shifted versions of the filter by the signal:

```{code-cell} ipython3
shift = 0                                          # Choose a shift,
inds = [(shift - n) % N for n in range(N)]         # ... and define the indices,
plot(i_rectangular_filter[inds], label="filter")   # ... to plot the shifted rectangular filter.
plot(impulse, label="impulse")                     # Plot the impulse,
legend()                                           # ... and compute the convolution at this shift.
title('Convolution = {:.4f}'.format(sum(i_rectangular_filter[inds] * impulse)))
ylim([-0.01, 0.1])
show()
</code></pre></div></div>

<p>When <code class="language-plaintext highlighter-rouge">shift = 0</code>, the filter begins with a peak at time index 0, and small oscillations are most apparent at lags near the beginning and end of the vector. As we (circularly) shift the filter, we move the filter peak to higher time indices (increase the value of <code class="language-plaintext highlighter-rouge">shift</code> in the code below to see this). When the filter peak reaches the impulse (<code class="language-plaintext highlighter-rouge">shift = 500</code>), the resulting summed product (i.e., the convolution) is large. Away from this time of large overlap, the resulting convolutions are small. The impulse response function is the result of these summed multiplications performed for all time shifts.</p>

<p>+++</p>

<p>The resulting impulse response function computed in the time domain through convolution (variable name <code class="language-plaintext highlighter-rouge">impulse_response_t</code>, where <code class="language-plaintext highlighter-rouge">_t</code> denotes time) is identical to the impulse response function computed in the frequency domain through element-by-element multiplication (variable name <code class="language-plaintext highlighter-rouge">impulse_response</code>); we can see this by plotting <code class="language-plaintext highlighter-rouge">impulse_response_t</code> on the same axes where we previously plotted <code class="language-plaintext highlighter-rouge">impulse_response</code>.</p>

<p>```{code-cell} ipython3
ax.plot(lag_axis, impulse_response_t, ‘–’, label=’impulse_response_t’)
ax.legend()
fig</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
We have now examined two equivalent methods of filter application: through multiplication in the frequency domain or through convolution in the time domain. Both approaches provide insight into the impact of the naive rectangular filter. The frequency domain representation is easier to interpret. We designed this filter in the frequency domain to eliminate signal components near 60 Hz, which we implemented through an abrupt decrease in the frequency domain representation of the filter. It’s relatively easy to envision that this filter eliminates signal features near &amp;plusmn;60 Hz and preserves features at other frequencies&lt;a href="#fig:4" class="fig"&gt;&lt;sup&gt;fig&lt;/sup&gt;&lt;img src="imgs/6-4.png"&gt;&lt;/a&gt;.

The time domain representation of the naive rectangular filter is more complicated. While the impact of the filter in the frequency domain is limited, the impact in the time domain is broad. The impulse response decays at times away from the impulse; however, these contributions do remain. This example illustrates the necessary trade-off between the time and frequency domains. Namely, the sharp transition bands, or roll-off in the frequency domain (i.e., the nearly vertical rectangular-shaped transitions) correspond to a broad impulse response function that extends over many lags in the time domain. There’s no escaping this fact: the sharper we make the filter’s transitions in the frequency domain, the broader its effects in time. Again, we make this trade-off to implement the sharp roll-off of the naive rectangular filter; the transition band is narrow (a precipitous drop) in frequency and therefore requires many values in time.

Through the interpretation of filtering as convolution in time, we gain additional insight into the naive rectangular filter’s impact. When we looked closely, we identified suspicious behavior in the; we found that after filtering, the large-amplitude discharge was surrounded by small-amplitude oscillations with frequency near 60 Hz. Under the interpretation of filtering as convolution, we expect that a sudden large change in the input signal (i.e., the brief discharge in the EEG) will clearly impact the resulting filtered signal across an extended interval of time. Indeed, because the brief EEG discharge is so large, the small amplitude oscillations surrounding the central peak of the impulse function are apparent in the filtered EEG signal. For these brief large-amplitude peaks in the EEG data, the temporal impact of the filter is obvious in the filtered signal. However, this temporal impact occurs throughout the filtered signal; using the naive rectangular filter, each time point in the original signal impacts every time point in the [filtered signal](#fig:5c)&lt;span class="fig"&gt;&lt;sup&gt;fig&lt;/sup&gt;&lt;img src="imgs/6-5c.png"&gt;&lt;/span&gt;.

We conclude this section by noting that these results are analogous to our discussion of the rectangular window function in [chapter 4](../04). In that chapter, we applied a rectangular taper in the time domain and showed that this produced broad effects in the frequency domain. Here, we instead apply an (inverted) rectangular taper in the frequency domain and find broad effects in the time domain. The fundamental concept is that the Fourier transform of a sharp transition in one domain (in this case, the abrupt edge of a rectangular taper) produces broad effects in the other domain.

+++

[Back to Top](#top)
#### A naive Hanning filter.

In the previous section, we developed and applied a naive rectangular filter. We used the word “rectangular” to indicate the rectangular shape of the [filter](#fig:4)&lt;span class="sup"&gt;fig&lt;img src="imgs/6-4.png"&gt;&lt;/span&gt; in the frequency domain. Although well-behaved in the frequency domain, the naive rectangular filter produces undesired effects in the time domain; namely, the filter’s sharp transitions in the frequency domain produce wide-ranging effects in the time domain. These long-range temporal effects are an unwanted feature of the filter. To reduce these effects, we propose an alternative filter that softens the sharp transitions in the frequency domain and makes these transitions more gradual. The idea is simple: replace the rectangular function in the original naive filter with a different, smoother function. In what follows we implement many of same procedures employed in the previous section and interpret how these changes affect the filtered EEG data.

Let’s begin our filter design in the frequency domain. Our goal is to eliminate the 60 Hz component (i.e., the electrical noise) from the EEG signal without introducing long-lasting temporal effects. To do so, instead of the naive rectangular function employed in our first filter, we’ll use a smooth Hanning function (first introduced in our computations of the spectrum in [chapter 4](../04)). First, we need to load the data and identify the indices corresponding to &amp;plusmn;60 Hz, and then apply a Hanning window centered at each of these indices. Some of the following commands are redundant with commands we used previously, but they are repeated here for completeness.

```{code-cell} ipython3
data = loadmat('EEG-1.mat')  # Load,
eeg = data['EEG']            # ... the EEG data,
t = data['t'][0]             # ... and the time axis.
x = eeg[0]                   # Analyze the first trial.
dt = t[1] - t[0]             # Define the sampling interval.
N = len(x)                   # Define the no. of points in a single trial.
df = 1 / (N * dt)            # Determine the frequency resolution.
fNQ = 1 / dt / 2             # Determine the Nyquist frequency.
faxis = fftfreq(N, dt)       # Construct the frequency axis.

win = 15                     # Set the size of the Hann window,
                             # ... and find indices within win of 60 Hz.
inds = (abs(faxis) &gt;= (60 - win * df)) &amp; (abs(faxis) &lt;= (60 + win * df))

hann_filter = np.ones_like(t) # Define filter in frequency domain.
hann_filter[inds] = np.hstack([1 - hanning(2 * win + 1), 1 - hanning(2 * win + 1)])

isorted = np.argsort(faxis)                  # Sort the frequency axis.
plot(faxis[isorted], hann_filter[isorted])   # Plot the filter.
xlim([-80, 80])
xlabel('Freq (Hz)')
title('Hanning filter')
savefig('imgs/6-8a')
show()
</code></pre></div></div>

<p>In this code, we load the EEG from the first trial (variable <code class="language-plaintext highlighter-rouge">x</code>) and create the frequency axis (variable <code class="language-plaintext highlighter-rouge">faxis</code>) to find the indices that correspond to frequencies at ±60 Hz. At these indices, we center a Hanning window, which sets the filter to 0 at ±60 and gradually returns to 1 away from these values (the parameter <code class="language-plaintext highlighter-rouge">win</code> sets the width of the window).</p>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> Plot the original naive rectangular filter on top of the new Hanning filter. Compare the frequency domain representations of the two filters. What differences do you observe?</p>

  <p><strong>A.</strong> Although both filters decrease to 0 near ±60 Hz, the Hanning filter returns gradually to 1, while the rectangular filter rapidly changes from 0 to 1. In other words, the roll-off is more gradual in the Hanning filter compared to the square filter.</p>

</div>

<p>+++</p>

<p>Let’s also examine the time domain representation of the new Hanning filter. To do so, we compute the impulse response.
<a id="fig:8b"></a></p>

<p>```{code-cell} ipython3
def convolution(impulse, filt):
    ‘’’
    Compute the impulse response of a filter (given in the 
    time domain) using convolution.
    ‘’’
    N = len(impulse)
    response = np.zeros_like(impulse)
    for ii in range(N):
        inds = [(ii + n) % N for n in range(N)]
        response[ii] = sum(impulse[inds] * filt)
    return response</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
```{code-cell} ipython3
impulse = np.zeros_like(x)              # Define the input signal,
impulse[N // 2] = 1                     # ... with impulse at the midpoint
i_hann_filter = ifft(hann_filter).real  # Transform filter to time domain,
                                        # ... and compute the impulse response by convolution.
impulse_response_t = convolution(i_hann_filter, impulse)
lag_axis = np.arange(-N/2, N/2) * dt    # Define the lag axis for plotting
plot(lag_axis, impulse_response_t)      # Display the result
xlabel('Time (s)')
ylabel('Impulse response')
ylim([-.03, .05])
savefig('imgs/6-8b')
show()
</code></pre></div></div>

<p>In this code, we first define the impulse signal and then convolve this impulse with the Hanning filter transformed to the time domain (using <code class="language-plaintext highlighter-rouge">ifft</code>).</p>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> Plot the time domain representation of the original naive rectangular filter on top of that of the new Hanning filter. Compare the two. What differences do you observe?</p>

  <p><strong>A.</strong> To answer this question, execute the commands below. You’ll find that both filters exhibit a large peak at time 0 s and are surrounded by small-amplitude 60 Hz oscillations. Compared to the naive rectangular filter, these oscillations are initially larger for the proposed Hanning filter. However, these oscillations quickly decay for the Hanning filter; after ±50 ms, the Hanning filter remains near zero.</p>

</div>

<p>```{code-cell} ipython3</p>
<h1 id="plot-the-time-domain-representations-of-the-naive-rectangular-and-hanning-filters">Plot the time domain representations of the naive rectangular and Hanning filters.</h1>
<p>plot(ifft(hann_filter).real,        label=”Hanning filter in time domain”)
plot(ifft(rectangular_filter).real, label=”Rectangular filter in time domain”)
legend()
ylim([-0.05,0.05])
xlim([0,500]);
xlabel(‘Time (indices)’)
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;div class="question"&gt;
    
**Q.** Compute the impulse response function of the Hanning filter without using the convolution function. Instead, only use the Fourier transform and the inverse Fourier transform. Do you find the same results as shown above? *Hint*: You should.

&lt;/div&gt;

+++

The more gradual roll-off in the frequency domain corresponds to a more localized impact in the time domain. Here again we are forced to trade desirable features in the time and frequency domains. In the Hanning filter, we forsake the sharp roll-off of the naive rectangular filter&amp;mdash;a desirable property&amp;mdash;for the more local temporal impact, also a desirable property.

Now, having visualized the new filter, let’s apply it to the EEG data. To do so, we follow the same procedure used to filter the EEG data with the naive rectangular filter.

```{code-cell} ipython3
xf = fft(x)                       # Transform data to frequency domain,
xf_filtered_h = xf * hann_filter  # ... apply Hanning filter,
xnew_h = ifft(xf_filtered_h).real # ... transform back to time domain,
                                  # ... and plot the results.
plot(t, xnew,   label="Rectangular filtered")
plot(t, xnew_h, label="Hanning filtered")
xlabel('Time (s)')
ylabel('Voltage (mV)')
ylim([-.3, .5])
legend()
savefig('imgs/6-9b')
show()
</code></pre></div></div>

<p>In the first three lines of code above, the EEG data are first transformed to the frequency domain using the Fourier transform. Then the Hanning filter is applied through element-by-element multiplication. Finally, the filtered signal is transformed back to the time domain using the inverse Fourier transform.</p>

<p>We can additionally compare the filters by looking at the spectra near 60 Hz:</p>

<p>```{code-cell} ipython3
plot(faxis[:N//2], 10 * np.log10(spectrum(x, t)), label=’x’)
plot(faxis[:N//2], 10 * np.log10(spectrum(xnew, t)), label=’rectangle filter’)
plot(faxis[:N//2], 10 * np.log10(spectrum(xnew_h, t)), label=’hanning filter’)
xlim([40, 80])
xlabel(‘Freq (Hz)’)
ylabel(‘Power (dB)’)
title(‘Power spectra’)
legend()
savefig(‘imgs/6-9a’)
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;div class="question"&gt;
    
**Q.** Compare the results of filtering the EEG data using the naive rectangular filter and the Hanning filter. How do the filters produce similar, and different, results?

**A.** Comparison of the resulting spectra shows a sharper and deeper decrease near the 60 Hz peak for the naive rectangular filtered EEG data. In this way, the naive rectangular filter appears to far outperform the Hanning filter; the stop-band of the naive rectangular filter is more focused on eliminating the 60 Hz signal we’d like to remove. The Hanning filter is broader and reduces frequency components extending ±10 Hz around the 60 Hz peak.

However, in the time domain, the Hanning filter is far superior. The example shown above illustrates the long-range temporal effects imposed by the naive rectangular filter. Near a brief large discharge in the (unfiltered) EEG data, both filters introduce rhythmic activity for an interval of time. For the Hanning filtered data, these oscillations are a bit larger. For the naive rectangular filtered data, these oscillations persist for a much longer duration; notice that small-amplitude (60 Hz) oscillations appear from time 0 s to time 0.4 s.

&lt;/div&gt;

+++

Having filtered the EEG data in two ways and analyzed the results, we may now make an important conclusion: the naive rectangular filter is a poor choice. Although this filter performs admirably in the frequency domain, the results in the time domain are unacceptable. The naive rectangular filter may confound our understanding of the EEG signal through incorporation of new, long-duration temporal effects in the filtered signal. These results suggest the Hanning filter is a better choice. **However, we do not recommend using this filter.** Instead, we recommend the much safer choice of using filters designed in preexisting software functions. We describe one example of this approach in the next section.

+++

[Back to Top](#top)
&lt;a id="advanced-filters"&gt;&lt;/a&gt;
### More Sophisticated Filtering

In the previous section, we designed two filters. To do so, we started in the frequency domain and applied concepts developed in previous modules when studying the spectrum (chapters [3](../03) and [4](../04)). We undertook this initial approach for one purpose: to build intuition. Developing such intuition is critical; without it, filtering would be hard to understand. However, in practice, we do not recommend the use of the naive rectangular filter or the Hanning filter. This point is so important, we further emphasize it.

&lt;div class="warning"&gt;

Do *not* use the naive rectangular filter or the Hanning filter on your data.

&lt;/div&gt;

Instead, we recommend using preexisting filter design methods provided for Python or other software. In this section, we illustrate the implementation and application of one such method. We continue to use the visualization techniques developed in the previous section to analyze the time and frequency domain representations of the implemented filter. We then apply the filter to the EEG data and examine the results.

#### The Finite Impulse Response (FIR) Filter: An Example.

The most common category of filter applied in neuroscience applications is the finite impulse response (FIR) filter. The name for this approach is actually quite informative. In the previous section, we defined the impulse response; it represents the response of the filter to a signal composed of only a single impulse. “Finite impulse response” indicates that the impulse response consists of only a finite number of nonzero terms. The naive rectangular filter was an example of an infinite impulse response; to represent the naive rectangular filter in the time domain requires an infinite number of terms.&lt;sup&gt;&lt;abbr title="In practice, all digital filters are finite. We have only a finite amount of computer memory in which to store the filter. In theory, the impulse response of the naive rectangular filter decays to zero as time approaches infinity and therefore contains nonzero contributions for an infinite number of terms."&gt;note&lt;/abbr&gt;&lt;/sup&gt; We found that such a broad response in the time domain produces unwanted temporal effects in the filtered signal. Here, we instead implement a filter with only a finite number of nonzero terms in the impulse response.

Before using packaged routines to create a FIR filter, we might consider how to design our own. A straightforward approach would be to start with an existing filter we developed (e.g., either the naive rectangular filter or the Hanning filter) and truncate the number of terms in the impulse response. By doing so, we would necessarily create a finite impulse response function; all terms beyond a chosen time point would be set to zero. We would therefore eliminate contributions to the filtered signal from inputs far into the past or future. That’s the right idea, but we do not pursue this approach. Instead, we use packaged functions. In this way, we leverage the expertise already inherent in these preexisting filter design approaches.

We focus specifically on the application of a lowpass FIR filter to the EEG data. We use the `firwin()` command in from the [SciPy Signal module](https://docs.scipy.org/doc/scipy/reference/signal.html) to design this filter and then apply it using the convolution function we defined earlier. We then visualize the filter and impulse response in the time and frequency domains. Let’s import the module, define useful parameters, and then design the filter:
&lt;a id="fig:10a"&gt;&lt;/a&gt;

```{code-cell} ipython3
n = 100                                        # Define the filter order.
Wn = 30 / fNQ                                  # Define the cutoff frequency,
b = firwin(n, Wn)                              # ... build the lowpass filter,
bz = np.pad(b, [N - n, 0], 'constant')         # ... amend the filter with leading zeros,
impulse_response = convolution(impulse, bz)  # ... and apply it to the impulse.

plot(lag_axis, impulse, label='impulse')
plot(lag_axis, impulse_response, label='impulse response')
legend()
ylim([-.02, .08])
show()
</code></pre></div></div>

<p>Before computing the convolution, we create an augmented vector (variable <code class="language-plaintext highlighter-rouge">bz</code>). This new vector consists of leading zeros, followed by the filter (variable <code class="language-plaintext highlighter-rouge">b</code>). The augmented vector has the same length (<code class="language-plaintext highlighter-rouge">N</code>) as the impulse signal (variable <code class="language-plaintext highlighter-rouge">impulse</code>), and therefore we can compute the element-by-element multiplication of these two vectors in the same way as we did for the naive rectangular and Hanning filters. Note that the nonzero values of the filter appear at the end of the augmented vector <code class="language-plaintext highlighter-rouge">bz</code>. To compute the convolution, we shift these nonzero values over the entire length of the augmented vector, and at each shift multiply element by element the two vectors and sum their product.</p>

<p>Visual inspection reveals the relation between the original impulse and the filtered impulse following application of the FIR filter. We notice an important difference between the impulse response of the FIR filter and the impulse responses of the naive rectangular and Hanning filters. For the FIR filter, the peak impulse response <em>follows</em> the impulse. The reason for this delay is that the FIR filter is <em>causal</em>; to compute the convolution at any time requires only past and current values of the input signal. The naive rectangular and Hanning filters required both past and future values of the input signal. Those filters were noncausal.</p>

<p>To further explore this idea, let’s examine in more detail the computation of the FIR filter. Notice that to design the filter we call the <code class="language-plaintext highlighter-rouge">firwin()</code> with two inputs. The first input specifies the filter order, which corresponds to the number of nonzero terms in the filter. We specify a filter order of <code class="language-plaintext highlighter-rouge">n=100</code>. We next specify the upper frequency for the lowpass filter, which we set to 30 Hz. Notice that the frequency is specified as a fraction of the Nyquist frequency. In this case, we implement a lowpass filter; this filter will pass frequencies below 30 Hz and stop frequencies above 30 Hz. We choose a lowpass filter in this case for physiological reasons; scalp EEG data are often corrupted by muscle artifacts at frequencies above 20–30 Hz. Therefore, in an attempt to better isolate true brain signals and extract an evoked response, we apply a lowpass filter to the EEG data.</p>

<p>+++</p>

<div class="python-note">

  <p><strong><em>Note</em></strong>: If we had wanted to make a highpass filter, we could have indicated this with additional arguments to <code class="language-plaintext highlighter-rouge">firwin()</code>; use <code class="language-plaintext highlighter-rouge">firwin?</code> to read the documentation.</p>

</div>

<p>+++</p>

<p>To examine this filter, let’s break down what it does and visualize it in the time and frequency domains. In the time domain, we have already computed the impulse response using the convolution:</p>

<p>```{code-cell} ipython3
plot(np.arange(0, N) * dt, impulse, label=’impulse’)                          # Plot the original impulse,
plot(np.arange(0, N) * dt, impulse_response, lw=3, label=”impulse response”)  # … and the impulse response.
ylim([-.02, .08])                                                             # … with axes labeled
legend()
savefig(‘imgs/6-10a’)
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Now, let's examine this computation closely to understand why there is a lag. To compute the FIR filter, we first constructed the augmented filter vector. To align the filter peak with the impulse requires that we (circularly) shift the augmented filter vector. In this example, the peak in the augmented filter vector (`bz`) occurs at index $N - n/2$, or equivalently, at time $(N - n/2) \cdot dt$ = 0.55 s, where $N$ is the length of the EEG data, and $n$ is the filter order. We must therefore (circularly) shift the augmented filter vector by $N/2 + n/2$, or equivalently, $(N/2 + n/2) \cdot dt$ = 0.55 s, to align it with the peak of the impulse (which occurs at index $N/2$, or equivalently, at time $N/2 \cdot dt$ = 0.5 s). The largest value in the resulting convolution therefore occurs at an index $n/2$ (or equivalently, 0.05 s) past the impulse in the original signal. The delay between the impulse and impulse response in the plot above corresponds to $n/2$ indices, or 0.05 s.

+++

&lt;div class="question"&gt;
    
**Q.** What are the implications of the delay induced by the FIR filter? How might this delay impact subsequent analysis?

**A.** We consider this question in more detail later in this module.

&lt;/div&gt;

+++

We may also examine the filter in the frequency domain. To do so, we compute and plot the *magnitude response*:
&lt;a id="fig:10b"&gt;&lt;/a&gt;

```{code-cell} ipython3
bf = fft(b, N);                 # Transform filter to frequency domain and compute the response
Mb = bf * bf.conj();            # ...and compute the magnitude response.
df = 1 / (N * dt)               # Define the frequency resolution,
faxis = fftfreq(N, dt);         # ...create frequency axis,
sort_order = np.argsort(faxis)  # ...with axes sorted,
plot(faxis[sort_order], Mb.real[sort_order])   # ...plot magnitude response.
xlim([-50, 50])
xlabel('Frequency (Hz)')
ylabel('Magnitude')
savefig('imgs/6-10b')
show()
</code></pre></div></div>

<p>We take the Fourier transform of the filter, with zero padding (see <a href="../04">chapter 4</a>) to match the size of the EEG data, and compute the product of the Fourier transform of the filter and its complex conjugate. We then define the frequency axis, and plot the sorted frequency axis to avoid any unwanted lines.</p>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> Describe the behavior of the FIR filter in the frequency domain. What frequencies are passed? What frequencies are stopped?</p>

  <p><strong>A.</strong> Inspection of the magnitude response shows that frequencies between approximately ±30 Hz are passed; within this interval, the magnitude response of the filter is above zero. Beyond this interval, the magnitude response decreases to zero. Frequencies greater than 30 Hz or less than -30 Hz are removed in the filtered signal.</p>

</div>

<p>+++</p>

<p>Having analyzed the filter through inspection of its impulse response and magnitude response, let’s now apply this filter to the EEG data:
<a id="fig:11a"></a></p>

<p>```{code-cell} ipython3
xnew_fir_conv = convolution(x, bz)                 # Apply the FIR filter to the data.
plot(t, x, label=’x’)                              # Plot the data,
plot(t, xnew_fir_conv, lw=4, label=’x filtered’)   # … and the filtered data,
legend()
xlabel(‘Time (s)’)                                 # … with axes labeled.
ylabel(‘Voltage (mV)’)
ylim(ymax=2)
savefig(‘imgs/6-11a’)</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Inspection of the resulting filtered signal reveals important features of the new time series. Perhaps the most prominent change is the large reduction in the 60 Hz electrical noise. Without the contamination of this noise, we now observe a transient oscillatory event near 0.5 s. As expected, the spectrum is now dominated by low-frequency activity, namely, rhythms below 30 Hz: 
&lt;a id="fig:11b"&gt;&lt;/a&gt;

```{code-cell} ipython3
plot(faxis[:N // 2], 10 * np.log10(spectrum(x, t)), label='x')                 # Spectrum of data.
plot(faxis[:N // 2], 10 * np.log10(spectrum(xnew_fir_conv, t)), label='x filtered') # Spectrum of filtered data.
xlim([0, 100])
ylim([-80, 0])
xlabel('Freq (Hz)')
ylabel('Power (dB)')
legend()
savefig('imgs/6-11b')
show()
</code></pre></div></div>

<p>Finally, let’s compare the filtered signal using the different filtering methods discussed:
<a id="fig:11c"></a></p>

<p>```{code-cell} ipython3
plot(t, xnew,     label=’rectangular filter’)         # Plot the results using the rectangular filter, 
plot(t, xnew_h,   label=’Hanning filter’)             # … the Hanning filter,
plot(t, xnew_fir_conv, label=’lowpass FIR filter’)    # … and the lowpass FIR.
ylim([-.3, .4])                                       # Narrow the y axis
legend()                                              # Label each line
xlabel(‘Time (s)’)                                    # Label the axes
ylabel(‘Voltage (mV)’)
savefig(‘imgs/6-11c’)
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
The lowpass filter alters the sharp, brief discharge in the original EEG signal (near 0.2 s) in two important ways. First, we directly observe the temporal shift introduced by the FIR filter; the peak in the filtered signal follows the large voltage deviation in the original signal by 0.05 s&lt;a class="sup" href="#fig:11a"&gt;fig&lt;img src="imgs/6-11a.png"&gt;&lt;/a&gt;). Second, the FIR filter acts to reduce and broaden the large voltage deviation in the original EEG signal, consistent with the impulse response for this filter&lt;a href="#fig:10a" class="sup"&gt;fig&lt;img src="imgs/6-10a.png"&gt;&lt;/a&gt;).

+++

&lt;div class="question"&gt;
    
**Q.** Why would a lowpass filter act to reduce and broaden a brief large discharge in the EEG?

**A.** Consider the spectrum of a simpler time series that consists of all zeros except for a single value of 1 at some time index; for example, the simple time series we use to compute the impulse response of a filter. The corresponding spectrum will have nonzero contributions at all frequencies, i.e., representing an impulse requires a combination of sinusoids at many frequencies. Conceptually, an impulse is difficult to represent as a sum of sinusoids. A single sinusoid exists (theoretically) for all time, and we’d somehow like to use these long-duration functions to represent a brief-duration impulse. If we now eliminate some of these sinusoids (e.g., by lowpass filtering the data) we corrupt the representation of the impulse; without these sinusoids, we’re no longer able to accurately represent the sharp, brief impulse in time. Instead, we create an impulse that’s broader and shorter.&lt;span class="sup"&gt;fig&lt;img src="imgs/6-10a.png"&gt;&lt;/span&gt; That’s the best we can do to represent the impulse with the sinusoids we’re given, i.e., the sinusoids with frequency less than 30 Hz. In this way, the lowpass filter acts to smooth the brief large discharge in time.

&lt;/div&gt;

+++

Finally, inspection of the filtered signal&lt;a href="#fig:11c" class="sup"&gt;fig&lt;img src="imgs/6-11c.png"&gt;&lt;/a&gt; reveals an important advantage over the naive rectangular filter. The small-amplitude 60 Hz activity produced by the naive rectangular filter does not appear in the FIR filtered data. Because the FIR filter acts more locally in time (the impulse response is finite), this filter does not produce the long-lasting temporal effects of the naive rectangular filter. We also note the clear delay induced by the FIR filter compared to the naive rectangular filter.

In the preceding code, we applied the FIR filter by computing the convolution. To conclude this section, we introduce a function from the [SciPy Signal module](https://docs.scipy.org/doc/scipy/reference/signal.html) to apply the FIR filter:

    xnew_lfilt = lfilter(b, 1, x)
    
Here, we call the function `lfilter()` with three arguments. The first argument is the FIR filter we designed at the beginning of this section using the `fir1` command. The second input (a value of 1) is appropriate for the FIR filter we designed here,&lt;sup&gt;&lt;abbr title="Different values for the second input allow specification of different filter types (e.g., a Butterworth filter) but are not considered here. Consult the documentation for more details."&gt;note&lt;/abbr&gt;&lt;/sup&gt; and the last input is the EEG signal from trial 1. Let's now plot the signal filtered in this way:

```{code-cell} ipython3
xnew_lfilt = lfilter(b, 1, x)                                    # Filter the signal using lfilter.
plot(t, xnew, label='rectangular filter')                        # Plot the results using the rectangular filter, 
plot(t, xnew_h, label='Hanning filter')                          # ... the Hanning filter,
plot(t, xnew_fir_conv, '--', label='lowpass FIR filter (conv)')  # ... and convolution with the lowpass FIR.
plot(t, xnew_lfilt, label='lowpass FIR filter (lfilter)')        # ... and using lfilter with the lowpass FIR.
ylim([-.3, .4])                             # Narrow the y axis
legend()                                    # Label each line
xlabel('Time (s)')                          # Label the axes
ylabel('Voltage (mV)')
savefig('imgs/6-11c')
show()
</code></pre></div></div>

<p>We see that after an initial transient, the filtered signal computed using the <code class="language-plaintext highlighter-rouge">lfilter()</code> function, and the filtered signal computed explicitly using the convolution produce the same result.</p>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> Apply the FIR filter to the EEG data without using convolution or <code class="language-plaintext highlighter-rouge">lfilter()</code>. Instead, only use the Fourier transform and inverse Fourier transform. Do you find results consistent with the other two computations? <em>Hint</em>: You should.</p>

</div>

<p>+++</p>

<p>To summarize, the design and application of a lowpass FIR filter can be performed in two simple steps:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>b = firwin(n, Wn)              # Design the lowpass filter, 
xnew_lfilt = lfilter(b, 1, x)  # ... and apply it to the signal x
</code></pre></div></div>

<p>To actually execute these lines of code, we must first define the filter parameters (i.e., the filter order and the cutoff frequency), but the essence of the filtering procedure is captured here. These two lines make the process of filter design and application simple but potentially obfuscate what the filter actually does. We therefore did not immediately implement a filter in this way. Instead, we first examined intuitive ideas for filter design (e.g., the naive rectangular filter and Hanning filter) and visualizations. We expect that these initial examples will provide insight to the packaged routines. In practice, application of these routines is typically the best choice when analyzing your own data.</p>

<p>+++</p>

<p><a href="#top">Back to Top</a></p>
<h3 id="whats-phase-got-to-do-with-it">What’s Phase Got to Do with It?<a id="phase"></a>
</h3>

<p>+++</p>

<p>We saw in the previous section that the FIR filter (implemented using the <code class="language-plaintext highlighter-rouge">lfilter()</code> function) introduced a time shift in the resulting signal; this shift appeared in both the <a href="#fig:10a" class="fig">impulse response<span><img src="imgs/6-10a.png"></span></a> and in application to the <a href="#fig:11a" class="fig">EEG signal<span><img src="imgs/6-11a.png"></span></a>. In many applications, we’re interested in the precise timing of neural events. For example, if we’d like to understand the EEG response following a stimulus presentation, we must carefully preserve the timing of EEG features. We discuss in <a href="../07">chapter 7</a> a specific context in which such timing of features is important to preserve (e.g., cross-frequency coupling). In these contexts and others, shifts in the EEG signal must be either well understood and accounted for, or avoided.</p>

<p>To assess how a filter impacts a signal, we develop another visualization technique. Recall that the Fourier transform of a signal consists of both a real and an imaginary component, or equivalently, a magnitude and phase in the complex plane (see, for example, the discussion of phase in <a href="../05">chapter 5</a>). We have already discussed how to visualize the <a href="#fig:10b" class="fig">magnitude response<span><img src="imgs/6-10b.png"></span></a> of a filter. We now consider a second visualization in the frequency domain: the phase response. The phase response is similar to the magnitude response in that both are frequency domain visualizations of the filter. The primary difference is that the phase response illustrates the impact of the filter on phase at each frequency.</p>

<p>Let’s compute the phase response for the lowpass FIR filter. We first construct this filter using the same procedure as above, and then compute and display the phase response. Repeating some commands from previous sections for completeness,</p>

<p>```{code-cell} ipython3
data = loadmat(‘EEG-1.mat’)             # Load the data,
eeg = data[‘EEG’]                       # … extract the relevant variables,
t = data[‘t’][0]
x = eeg[0]                              # … and analyze the first trial.</p>

<p>N = len(x)                              # Define no. of points in trial.
dt = t[1] - t[0]                        # Define the sampling interval.
fNQ = 1 / dt / 2                        # Define the Nyquist frequency,
df = 1 / (N * dt)                       # … and the frequency resolution,
faxis = fftfreq(N, dt);                 # … create frequency axis,
sort_order = np.argsort(faxis)          # … with axes sorted.</p>

<p>n = 100                                 # Define the filter order,
Wn = 30 / fNQ                           # … specify the cutoff frequency,
b = firwin(n, Wn)                       # … build lowpass filter.
bf = fft(b, N)                          # Transform filter to frequency domain,
plot(faxis[sort_order], angle(bf[sort_order]))  # … and plot phase response.</p>

<p>xlim([-30, 30])                         # Examine a specific frequency range,
xlabel(‘Frequency (Hz)’)                # … with axes labeled.
ylabel(‘Phase (rad)’)
savefig(‘imgs/6-12a’)
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
We first load the data and define the frequency axis. We then construct the lowpass FIR filter and plot the phase response versus frequency (with axes sorted to avoid spurious features in the plot). Note that we use the function `angle()` to determine the phase of the vector `bf`. We focus on the passband (from -30 Hz to 30 Hz) because signals outside of this band are greatly reduced by the filter and not relevant in the filtered signal.

+++

&lt;div class="question"&gt;
    
**Q.** Examine the phase response. How does the phase vary with frequency within the passband (i.e., for frequencies between &amp;plusmn;30 Hz)?

**A.** Visual inspection reveals that the phase response varies with frequency. This variation is linear except for discrete jumps occurring at &amp;plusmn;$\pi$. To make this linear variation clear, we can unwrap the phase:

    plot(faxis[sort_order], np.unwrap(angle(bf[sort_order])))
    
Notice the application of the `unwrap` function to the angle computed in this line of code. With the phase unwrapped, the smooth and linear variation in the phase response versus frequency becomes clear. The wrapped phase response allows us to identify frequencies at which the filter phase advances the signal (e.g., when the phase response is positive, such as at 15 Hz), when the filter phase delays the signal (e.g., when the phase response is negative, such as at 25 Hz), or when the filter leaves the phase unchanged (e.g., when the phase is zero, such as at 20 Hz).

```{code-cell} ipython3
plot(faxis[sort_order], np.unwrap(angle(bf[sort_order])))  # Plot the unwrapped phase response
xlim([-30, 30])                         # Examine a specific frequency range,
xlabel('Frequency (Hz)')                # ... with axes labeled.
ylabel('Phase (rad)')
savefig('imgs/6-12b')
show()
</code></pre></div></div>

<p>Analysis of the phase response for the FIR filter shows that, consistent with our observations of the impulse response and filtered EEG data, the FIR filter alters the phase of the original signal. To eliminate this shift introduced by the filter, we apply the same filter twice to the data. First, we apply the FIR filter to the original input signal, just as we did to create the lowpass filtered EEG. This filtering operation introduces a shift (of size n/2 indices, or 0.05 s for our data) in the resulting EEG (e.g., <a href="#fig:10a" class="fig">see above<span><img src="imgs/6-10a.png"></span></a>). Second, we reverse the filtered signal and then apply this same FIR filter to the reversed sequence. The outcome of this second filtering operation is our desired signal: the filtered data without the phase shift.
<a id="fig:13"></a></p>

<p>```{code-cell} ipython3
x1 = lfilter(b, 1, x)             # Apply the filter to the EEG data,
x1 = np.flip(x1)                  # … reverse the sequence,
x2 = lfilter(b, 1, x1)            # … reapply the filter,
x2 = np.flip(x2);                 # … and reverse the sequence.</p>

<p>fig, ax = subplots()              # Plot the results
ax.plot(t, x, label=’x’)
ax.plot(t, xnew_fir_conv, lw=5, label=’x filtered once’)
ax.plot(t, x2, lw=5, label=’x filtered twice’)</p>

<p>ylim([-1.5, 2.5])                 # Narrow the vertical axis,
xlabel(‘Time (s)’)                # … and label the axes.
ylabel(‘Voltage (mV)’)
legend()
savefig(‘imgs/6-13’)
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
In these lines of code, we apply the FIR filter using `lfilter()`.The first line of code applies the filter once, and the resulting filtered signal is phase shifted relative to the original EEG. We then reverse the filtered signal. To do so, we redefine the variable `x1` using `np.flip()` to reverse the sequence. We then filter the reversed sequence, and reverse the result. The resulting double-filtered (and double-reversed) signal no longer exhibits phase distortion relative to the EEG; prominent features in the original EEG signal and the zero-phase filtered signal, such as the large-amplitude discharge, appear better aligned.

In general, in neuroscience applications, it’s often useful to remove phase distortion through zero-phase filtering. The [SciPy Signal module](https://docs.scipy.org/doc/scipy/reference/signal.html) provides a simple function to perform zero-phase filtering,

    xnew_filtfilt = filtfilt(b, 1, x)  # Perform zero-phase filtering
    
The `filtfilt()` function applies the lowpass FIR filter defined by the parameters `b` to the data in the forward and reverse directions, and (ignoring transients at the beginning and end of the signal) matches our explicit approach to zero-phase filtering.

```{code-cell} ipython3
ax.plot(t, filtfilt(b, 1, x), '--', label='x filtfilt')
ax.legend()
fig
</code></pre></div></div>

<p>In the next section, we apply these commands to complete our analysis of the EEG signal.</p>

<p>Before completing this section, let’s briefly consider an intuitive argument to motivate the procedure for performing zero-phase filtering. Consider the impulse response for the lowpass FIR filter of order $n = 100$ we implemented previously<a href="#fig:10a" class="sup">fig<img src="imgs/6-10a.png"></a>. An impulse at index $k$ will result in a peak at index $k + n/2$ in the filtered signal; the first filtering operation shifts the index of the peak by $n/2$. Now, consider reversing the filtered signal. For concreteness, let’s consider the case where the impulse occurs at index 800 (i.e., k = 800) and the total length of the signal is 2,000 indices. After applying the filter, the peak will occur at index $k + n/2 = 850$. Now, reverse this filtered signal; the peak will then occur at index $2000 - 850 = 1150$. We then filter this new signal, which again shifts the index of the peak by $n/2$; the new peak then occurs at index $1150 + n/2 = 1200$. Finally, we reverse the signal once more; the peak index becomes $2000 - 1200 = 800$. Through this simple example, we gain some intuition for the zero-phase filtering process. By applying the filter twice and reversing the signal appropriately, we maintain the timing of features in the original input signal.</p>

<p>Does applying the same filter twice to the signal impacts the results? Yes. Each time we apply the filter, we convolve the signal with the coefficients <code class="language-plaintext highlighter-rouge">b</code> determined here for the lowpass FIR filter. Each application changes the resulting signal. However, the additional distortion produced by filtering twice is compensated by the elimination of phase distortion.</p>

<p>+++</p>

<p><a href="#top">Back to Top</a></p>
<h3 id="analysis-of-the-filtered-eeg-data">Analysis of the Filtered EEG Data<a id="analysis"></a>
</h3>

<p>+++</p>

<p>Having introduced some basic filtering concepts, let’s now return to the EEG data. Our primary scientific goal is to determine whether the provided EEG data exhibit an evoked response. Our initial analysis hinted that <a href="#fig:3" class="fig">an evoked response might occur<span><img src="imgs/6-3a.png"></span></a> but was hidden by the large electrical noise—and perhaps other noise—inherent in the EEG data. To reduce this noise, let’s examine the lowpass filtered EEG signal. We choose a lowpass filter to both reduce the 60 Hz electrical noise and reduce other activities associated with nonbrain signals (e.g., muscle artifacts) common in EEG data. In retrospect, the design and application of a lowpass filter with cutoff frequency is now straightforward.</p>

<p>```{code-cell} ipython3
data = loadmat(‘EEG-1.mat’)    # Load the EEG data.
eeg = data[‘EEG’]
t = data[‘t’][0]</p>

<p>dt = t[1] - t[0]               # Define the sampling interval.
fNQ = 1 / dt / 2               # Determine the Nyquist frequency.
K = len(eeg)                   # Determine no. of trials.</p>

<p>n = 100                        # Define the filter order
Wn = 30 / fNQ                  # … and specify the cutoff frequency,
b = firwin(n, Wn)              # … build lowpass filter.
eeg_lo = np.array([filtfilt(b, 1, eeg[k]) for k in range(K)])  # Zero-phase filter each trial</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Here we use the function `firwin()` to design the filter and the function `filtfilt()` to apply the filter with zero-phase distortion. The design and application of the filter to each trial requires only a few lines of code (including the for-loop). However, we now perform this analysis with a thorough understanding of how the filter behaves; we examined its
&lt;a href="#fig:10a" class="fig"&gt;impulse response&lt;span&gt;&lt;img src="imgs/6-10a.png"&gt;&lt;/span&gt;&lt;/a&gt;,
&lt;a href="#fig:10b" class="fig"&gt;magnitude response&lt;span&gt;&lt;img src="imgs/6-10b.png"&gt;&lt;/span&gt;&lt;/a&gt;, and &lt;a href="#fig:12" class="fig"&gt;phase response&lt;span&gt;&lt;img src="imgs/6-12a.png"&gt;&lt;/span&gt;&lt;/a&gt;. Let’s now analyze the resulting filtered EEG data by computing the evoked response and average spectrum.
&lt;a id="fig:14"&gt;&lt;/a&gt;

```{code-cell} ipython3
mn = eeg_lo.mean(0)      # Compute mean of filtered EEG across trials (ERP)
sd = eeg_lo.std(0)       # Compute std of filtered EEG data across trials.
sdmn = sd / np.sqrt(K);  # Compute the std of the mean.

plot(t, mn)                    # Plot the ERP of the filtered data
plot(t, mn + 2 * sdmn, 'r:');  # ... and the confidence intervals,
plot(t, mn - 2 * sdmn, 'r:');
xlabel('Time [s]')             # ... and label the axes.
ylabel('Voltage [ mV]')
title('Evoked response')
savefig('imgs/6-14a')
show()
</code></pre></div></div>

<p>```{code-cell} ipython3
def spectrum(x, t, hann=True):
    ‘’’
    Define a function that computes the power spectrum 
    for any given trial data (x) and corresponding sample time (t).
    ‘’’
    dt = t[1] - t[0]
    T = t[-1]
    xh = hanning(len(x)) * (x - x.mean()) if hann else x - x.mean()
    xf = rfft(xh)[:-1]
    Sxx = 2 * dt ** 2 / T * (xf * xf.conj())
    return Sxx.real</p>

<p>N = len(t)                             # Define the number of time points per trial.
faxis = fftfreq(N, dt)[:N // 2]        # Define the positive frequency axis,
Sxx = [spectrum(trial, t, False) for trial in eeg_lo]  # Compute the spectrum for each trial.
Sxxmn = np.array(Sxx).mean(0)          # Convert the result into an array and compute the mean.
semilogx(faxis, 10 * np.log10(Sxxmn))  # Plot the result in decibels vs frequency,
xlim([df, 100])                        # … in limited frequency range,
ylim([-60, 0])                         # … and a limited power range,
xlabel(‘Frequency [Hz]’)               # … with axes labeled.
ylabel(‘Power [dB]’)
title(‘Trial averaged spectrum’)
savefig(‘imgs/6-14b’)
show()
```</p>

<div class="question">

  <p><strong>Q.</strong> Compare the <a href="#fig:3" class="fig">evoked response<span><img src="imgs/6-3a.png"></span></a> and <a href="#fig:3" class="fig">spectrum<span><img src="imgs/6-3b.png"></span></a> of the original EEG data to the evoked response and spectrum of the filtered data. What features are similar? What features differ?</p>

  <p><strong>A.</strong> To compute the evoked response and average spectrum, we apply the same procedures utilized for the original data (see code <a href="#evoked-response">above</a>). We now find that between approximately 0.4 s and 0.6 s, the filtered EEG signal exhibits a signifiant ERP; the 95% confidence intervals of the ERP now exclude zero in this range. We are therefore happy to report to our collaborator evidence for a significant ERP in the filtered EEG data. We also note the reduced impact in the ERP of the large, brief discharges that appear in individual trials. In the original EEG data, each discharge from an individual trial was so large that the <a href="#fig:3" class="fig">impact on the ERP was dramatic<span><img src="imgs/6-3a.png"></span></a> (e.g., consider times near 0.2 s and near 0.8 s). In the filtered EEG data, these discharges have been smoothed, and their impact greatly reduced in the ERP.</p>

  <p>Inspection of the average spectrum for the filtered EEG data reveals power at low frequencies and perhaps a small peak at 15–25 Hz, as observed in the unfiltered EEG data. Again, we note that the approximately 15–25 Hz peak in the spectrum is consistent with the period of the transient rhythmic discharge in the ERP. The filtered data exhibit much less power spectral density at higher frequencies compared to the original EEG; this is what we expect following application of the lowpass filter.</p>

</div>

<p>+++</p>

<p><a href="#top">Back to Top</a></p>
<h2 id="summary">Summary<a id="summary"></a>
</h2>

<p>+++</p>

<p>We began this chapter with visual analysis of the single-trial data and computation of an ERP and trial-averaged spectrum. The spectrum revealed a large peak at 60 Hz, consistent with visual inspection of the single-trial data. The ERP showed some suggestive evidence for an evoked response; however, we did not find a significant effect. We made an initial conjecture that an interesting evoked response might occur in the data but was hidden by the large-amplitude 60 Hz noise.</p>

<p>To isolate the evoked response, we then focused on reducing the 60 Hz activity in the signal. We introduced the notion of filtering. We put forward two naive approaches, the naive rectangular filter, and the naive Hanning filter and developed these approaches in great detail. We defined the notion of an impulse response and examined how filtering may be equivalently applied in the frequency domain (through multiplication) or in the time domain (through convolution). Through these example filters, we observed the trade-offs that occur in the time and frequency domains. In particular, we observed that the sharp edge in the frequency domain of the naive rectangular filter created long-lasting effects in the time domain, acting to distort the original signal.</p>

<p>We then discussed the application of a finite impulse response (FIR) filter to the data. We showed how this filter may be easily defined and applied in Python using packaged functions. We discussed procedures to visualize a filter’s behavior, including the magnitude response and the phase response. Finally, we discussed the importance of zero-phase filtering.</p>

<p>We concluded by reanalyzing the EEG data. To do so, we first lowpass filtered the data and then computed the evoked response and trial-averaged spectrum. After filtering, we found a significant evoked response in the data. Consistent with our initial conjecture, the evoked response was hidden by the high-amplitude 60 Hz noise present in the original signal. Upon filtering to remove this noise, the evoked response became clear.</p>

<p>The design and application of filters is an enormous and rich field of study. The goal of this chapter is not a thorough discussion of filtering. Instead, we introduced only a handful of filtering concepts that motivate a basic understanding of filtering. These concepts extend directly from ideas developed to compute the spectrum in chapters <a href="../03">3</a> and <a href="../04">4</a>. Through tools such as the Fourier transform and convolution, we are able to visualize and apply filters in the frequency and time domains. These same tools apply and provide context for alternative approaches to filtering. For further details in the design and application of filters see [<a href="https://doi.org/10.1017/CBO9780511622762" target="_blank" rel="noopener noreferrer">Percival &amp; Walden, 1998</a>, <a href="https://buprimo.hosted.exlibrisgroup.com/permalink/f/1du03mk/ALMA_BOSU121668583370001161" target="_blank" rel="noopener noreferrer">Priestley, 1981</a>]. We apply filters in <a href="../07">chapter 7</a> to assess cross-frequency coupling in neural field data.</p>

<p><a href="#top">Back to Top</a></p>

            </div>
            <div class="c-textbook__footer" id="textbook_footer">
              
<nav class="c-page__nav">
  

  
</nav>

              <footer>
  <p class="footer">This page was created by <a href="https://github.com/jupyter/jupyter-book/graphs/contributors" target="_blank" rel="noopener noreferrer">The Jupyter Book Community</a></p>
</footer>

            </div>

        </main>
</div>
      
    
  </body>
</html>
