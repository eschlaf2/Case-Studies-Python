<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>Case Studies in Neural Data Analysis</title>
  <meta name="description" content="# The Event-Related Potential *for the practicing neuroscientist*+++    _**Synopsis**_ **Data:** 1 s of scalp EEG data sampled at 500 Hz during 1,000 trials ...">

  <link rel="canonical" href="https://mark-kramer.github.io/Case-Studies-Python/content/02/the-event-related-potential.html">
  <link rel="alternate" type="application/rss+xml" title="Case Studies in Neural Data Analysis" href="https://mark-kramer.github.io/Case-Studies-Python/feed.xml">

  <meta property="og:url"         content="https://mark-kramer.github.io/Case-Studies-Python/content/02/the-event-related-potential.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Case Studies in Neural Data Analysis" />
<meta property="og:description" content="# The Event-Related Potential *for the practicing neuroscientist*+++    _**Synopsis**_ **Data:** 1 s of scalp EEG data sampled at 500 Hz during 1,000 trials ..." />
<meta property="og:image"       content="https://mark-kramer.github.io/Case-Studies-Python/images/logo/logo.png" />

<meta name="twitter:card" content="summary">


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage": "https://mark-kramer.github.io/Case-Studies-Python/content/02/the-event-related-potential.html",
  "headline": "Case Studies in Neural Data Analysis",
  "datePublished": "2020-06-12T15:51:41-04:00",
  "dateModified": "2020-06-12T15:51:41-04:00",
  "description": "# The Event-Related Potential *for the practicing neuroscientist*+++    _**Synopsis**_ **Data:** 1 s of scalp EEG data sampled at 500 Hz during 1,000 trials ...",
  "author": {
    "@type": "Person",
    "name": "Mark Kramer and Uri Eden"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "https://mark-kramer.github.io/Case-Studies-Python",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "https://mark-kramer.github.io/Case-Studies-Python",
    "height": 60,
    "width": 60
  }
}

  </script>
  <link rel="stylesheet" href="/Case-Studies-Python/assets/css/styles.css">

  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="/Case-Studies-Python/images/logo/favicon.ico">

  <!-- MathJax Config -->
  <!-- Allow inline math using $ and automatically break long math lines -->
<!-- (mostly) copied from nbconvert configuration -->
<!-- https://github.com/jupyter/nbconvert/blob/master/nbconvert/templates/html/mathjax.tpl -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true
    },
    // Center justify equations in code and markdown cells. Elsewhere
    // we use CSS to left justify single line equations in code cells.
    displayAlign: 'center',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}},
        linebreaks: { automatic: true },
    },
    
});
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML' async></script>


  <!-- DOM updating function -->
  <script src="/Case-Studies-Python/assets/js/page/dom-update.js"></script>

  <!-- Selectors for elements on the page -->
  <script src="/Case-Studies-Python/assets/js/page/documentSelectors.js"></script>

  <!-- Define some javascript variables that will be useful in other javascript -->
  <script>
    const site_basename = '/Case-Studies-Python';
  </script>

  <!-- Add AnchorJS to let headers be linked -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js" async></script>
  <script src="/Case-Studies-Python/assets/js/page/anchors.js" async></script>

  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/turbolinks/5.2.0/turbolinks.js" async></script>
  <meta name="turbolinks-cache-control" content="no-cache">

  <!-- Load nbinteract for widgets -->
  

  <!-- Load Thebelab for interactive widgets -->
  <!-- Include Thebelab for interactive code if it's enabled -->


<!-- Display Thebelab button in each code cell -->
<script>
/**
 * Set up thebelab button for code blocks
 */

const thebelabCellButton = id =>
  `<a id="thebelab-cell-button-${id}" class="btn thebebtn o-tooltip--left" data-tooltip="Interactive Mode">
    <img src="/Case-Studies-Python/assets/images/edit-button.svg" alt="Start thebelab interactive mode">
  </a>`


const addThebelabButtonToCodeCells =  () => {

  const codeCells = document.querySelectorAll('div.input_area > div.highlight:not(.output) pre')
  codeCells.forEach((codeCell, index) => {
    const id = codeCellId(index)
    codeCell.setAttribute('id', id)
    if (document.getElementById("thebelab-cell-button-" + id) == null) {
      codeCell.insertAdjacentHTML('afterend', thebelabCellButton(id));
    }
  })
}

initFunction(addThebelabButtonToCodeCells);
</script>


<script src="https://unpkg.com/thebelab@latest/lib/index.js" async></script>
<script>
    /**
     * Add attributes to Thebelab blocks
     */

    const initThebelab = () => {
        const addThebelabToCodeCells = () => {
            console.log("Adding thebelab to code cells...");
            // If Thebelab hasn't loaded, wait a bit and try again. This
            // happens because we load ClipboardJS asynchronously.
            if (window.thebelab === undefined) {
                setTimeout(addThebelabToCodeCells, 250)
            return
            }

            // If we already detect a Thebelab cell, don't re-run
            if (document.querySelectorAll('div.thebelab-cell').length > 0) {
                return;
            }

            // Find all code cells, replace with Thebelab interactive code cells
            const codeCells = document.querySelectorAll('.input_area pre')
            codeCells.forEach((codeCell, index) => {
                const id = codeCellId(index)

                // Clean up the language to make it work w/ CodeMirror and add it to the cell
                dataLanguage = ""
                dataLanguage = detectLanguage(dataLanguage);
                codeCell.setAttribute('data-language', dataLanguage)
                codeCell.setAttribute('data-executable', 'true')

                // If the code cell is hidden, show it
                var inputCheckbox = document.querySelector(`input#hidebtn${codeCell.id}`);
                if (inputCheckbox !== null) {
                    setCodeCellVisibility(inputCheckbox, 'visible');
                }
            });

            // Remove the event listener from the page so keyboard press doesn't
            // Change page
            document.removeEventListener('keydown', initPageNav)
            keyboardListener = false;

            // Init thebelab
            thebelab.bootstrap();

            // Remove copy buttons since they won't work anymore
            const copyAndThebeButtons = document.querySelectorAll('.copybtn, .thebebtn')
            copyAndThebeButtons.forEach((button, index) => {
                button.remove();
            });

            // Remove outputs since they'll be stale
            const outputs = document.querySelectorAll('.output *, .output')
            outputs.forEach((output, index) => {
                output.remove();
            });

            // Find any cells with an initialization tag and ask ThebeLab to run them when ready
            var thebeInitCells = document.querySelectorAll('div.tag_thebelab-init');
            thebeInitCells.forEach((cell) => {
                console.log("Initializing ThebeLab with cell: " + cell.id);
                cell.querySelector('.thebelab-run-button').click();
            });
        }

        // Add event listener for the function to modify code cells
        const thebelabButtons = document.querySelectorAll('[id^=thebelab], [id$=thebelab]')
        thebelabButtons.forEach((thebelabButton,index) => {
            if (thebelabButton === null) {
                setTimeout(initThebelab, 250)
                return
            };
            thebelabButton.addEventListener('click', addThebelabToCodeCells);
        });
    }

    // Initialize Thebelab
    initFunction(initThebelab);

// Helper function to munge the language name
var detectLanguage = (language) => {
    if (language.indexOf('python') > -1) {
        language = "python";
    }
    return language;
}
</script>



  <!-- Load the auto-generating TOC (non-async otherwise the TOC won't load w/ turbolinks) -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.8.1/tocbot.min.js" async></script>
  <script src="/Case-Studies-Python/assets/js/page/tocbot.js"></script>

  <!-- Google analytics -->
  


  <!-- Clipboard copy button -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script>

  <!-- Load custom website scripts -->
  <script src="/Case-Studies-Python/assets/js/scripts.js" async></script>

  <!-- Load custom user CSS and JS  -->
  <script src="/Case-Studies-Python/assets/custom/custom.js" async></script>
  <link rel="stylesheet" href="/Case-Studies-Python/assets/custom/custom.css">

  <!-- Update interact links w/ REST param, is defined in includes so we can use templates -->
  
<script>
/**
  * To auto-embed hub URLs in interact links if given in a RESTful fashion
 */

function getJsonFromUrl(url) {
  var query = url.split('?');
  if (query.length < 2) {
    // No queries so just return false
    return false;
  }
  query = query[1];
  // Collect REST params into a dictionary
  var result = {};
  query.split("&").forEach(function(part) {
    var item = part.split("=");
    result[item[0]] = decodeURIComponent(item[1]);
  });
  return result;
}
    
function dict2param(dict) {
    params = Object.keys(dict).map(function(k) {
        return encodeURIComponent(k) + '=' + encodeURIComponent(dict[k])
    });
    return params.join('&')
}

// Parse a Binder URL, converting it to the string needed for JupyterHub
function binder2Jupyterhub(url) {
  newUrl = {};
  parts = url.split('v2/gh/')[1];
  // Grab the base repo information
  repoinfo = parts.split('?')[0];
  var [org, repo, ref] = repoinfo.split('/');
  newUrl['repo'] = ['https://github.com', org, repo].join('/');
  newUrl['branch'] = ref
  // Grab extra parameters passed
  params = getJsonFromUrl(url);
  if (params['filepath'] !== undefined) {
    newUrl['subPath'] = params['filepath']
  }
  return dict2param(newUrl);
}

// Filter out potentially unsafe characters to prevent xss
function safeUrl(url)
{
   return String(encodeURIComponent(url))
            .replace(/&/g, '&amp;')
            .replace(/"/g, '&quot;')
            .replace(/'/g, '&#39;')
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;');
}

function addParamToInternalLinks(hub) {
  var links = document.querySelectorAll("a").forEach(function(link) {
    var href = link.href;
    // If the link is an internal link...
    if (href.search("https://mark-kramer.github.io") !== -1 || href.startsWith('/') || href.search("127.0.0.1:") !== -1) {
      // Assume we're an internal link, add the hub param to it
      var params = getJsonFromUrl(href);
      if (params !== false) {
        // We have REST params, so append a new one
        params['jupyterhub'] = hub;
      } else {
        // Create the REST params
        params = {'jupyterhub': hub};
      }
      // Update the link
      var newHref = href.split('?')[0] + '?' + dict2param(params);
      link.setAttribute('href', decodeURIComponent(newHref));
    }
  });
  return false;
}


// Update interact links
function updateInteractLink() {
    // hack to make this work since it expects a ? in the URL
    rest = getJsonFromUrl("?" + location.search.substr(1));
    jupyterHubUrl = rest['jupyterhub'];
    var hubType = null;
    var hubUrl = null;
    if (jupyterHubUrl !== undefined) {
      hubType = 'jupyterhub';
      hubUrl = jupyterHubUrl;
    }

    if (hubType !== null) {
      // Sanitize the hubUrl
      hubUrl = safeUrl(hubUrl);

      // Add HTTP text if omitted
      if (hubUrl.indexOf('http') < 0) {hubUrl = 'http://' + hubUrl;}
      var interactButtons = document.querySelectorAll("button.interact-button")
      var lastButton = interactButtons[interactButtons.length-1];
      var link = lastButton.parentElement;

      // If we've already run this, skip the link updating
      if (link.nextElementSibling !== null) {
        return;
      }

      // Update the link and add context div
      var href = link.getAttribute('href');
      if (lastButton.id === 'interact-button-binder') {
        // If binder links exist, we need to re-work them for jupyterhub
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // If localhost, assume we're working from a local Jupyter server and remove `/hub`
          first = [hubUrl, 'git-sync'].join('/')
        } else {
          first = [hubUrl, 'hub', 'user-redirect', 'git-sync'].join('/')
        }
        href = first + '?' + binder2Jupyterhub(href);
      } else {
        // If interact button isn't binderhub, assume it's jupyterhub
        // If JupyterHub links, we only need to replace the hub url
        href = href.replace("", hubUrl);
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // Assume we're working from a local Jupyter server and remove `/hub`
          href = href.replace("/hub/user-redirect", "");
        }
      }
      link.setAttribute('href', decodeURIComponent(href));

      // Add text after interact link saying where we're launching
      hubUrlNoHttp = decodeURIComponent(hubUrl).replace('http://', '').replace('https://', '');
      link.insertAdjacentHTML('afterend', '<div class="interact-context">on ' + hubUrlNoHttp + '</div>');

      // Update internal links so we retain the hub url
      addParamToInternalLinks(hubUrl);
    }
}

runWhenDOMLoaded(updateInteractLink)
document.addEventListener('turbolinks:load', updateInteractLink)
</script>


  <!-- Lunr search code - will only be executed on the /search page -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.6/lunr.min.js" async></script>
  <script>var initQuery = function() {
  // See if we have a search box
  var searchInput = document.querySelector('input#lunr_search');
  if (searchInput === null) {
    return;
  }

  // Function to parse our lunr cache
  var idx = lunr(function () {
    this.field('title')
    this.field('excerpt')
    this.field('categories')
    this.field('tags')
    this.ref('id')

    this.pipeline.remove(lunr.trimmer)

    for (var item in store) {
      this.add({
        title: store[item].title,
        excerpt: store[item].excerpt,
        categories: store[item].categories,
        tags: store[item].tags,
        id: item
      })
    }
  });

  // Run search upon keyup
  searchInput.addEventListener('keyup', function () {
    var resultdiv = document.querySelector('#results');
    var query = document.querySelector("input#lunr_search").value.toLowerCase();
    var result =
      idx.query(function (q) {
        query.split(lunr.tokenizer.separator).forEach(function (term) {
          q.term(term, { boost: 100 })
          if(query.lastIndexOf(" ") != query.length-1){
            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })
          }
          if (term != ""){
            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })
          }
        })
      });

      // Empty the results div
      while (resultdiv.firstChild) {
        resultdiv.removeChild(resultdiv.firstChild);
      }

    resultdiv.insertAdjacentHTML('afterbegin', '<p class="results__found">'+result.length+' Result(s) found</p>');
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].teaser){
        var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<div class="archive__item-teaser">'+
                '<img src="'+store[ref].teaser+'" alt="">'+
              '</div>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      else{
    	  var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      resultdiv.insertAdjacentHTML('beforeend', searchitem);
    }
  });
};

initFunction(initQuery);
</script>

  <!-- Load JS that depends on site variables -->
  <script src="/Case-Studies-Python/assets/js/page/copy-button.js" async></script>

  <!-- Hide cell code -->
  <script src="/Case-Studies-Python/assets/js/page/hide-cell.js" async></script>

  <!-- Printing the screen -->
  <!-- Include nbinteract for interactive widgets -->
<script src="https://printjs-4de6.kxcdn.com/print.min.js" async></script>
<script>
printContent = () => {
    // MathJax displays a second version of any math for assistive devices etc.
    // This prevents double-rendering in the PDF output.
    var ignoreAssistList = [];
    assistives = document.querySelectorAll('.MathJax_Display span.MJX_Assistive_MathML').forEach((element, index) => {
        var thisId = 'MathJax-assistive-' + index.toString();
        element.setAttribute('id', thisId);
        ignoreAssistList.push(thisId)
    });

    // Print the actual content object
    printJS({
        printable: 'textbook_content',
        type: 'html',
        css: "/Case-Studies-Python/assets/css/styles.css",
        style: "#textbook_content {padding-top: 40px};",
        scanStyles: false,
        targetStyles: ["*"],
        ignoreElements: ignoreAssistList,
        documentTitle: "Made with Jupyter Book"
    })
};

initPrint = () => {
    document.querySelector('#interact-button-print').addEventListener('click', printContent)
}

initFunction(initPrint)
</script>

</head>

  <body>
    <!-- Include the ThebeLab config so it gets reloaded on each page -->
    <script type="text/x-thebe-config">{
    requestKernel: true,
    binderOptions: {
    repo: "mark-kramer/Case-Studies-Python",
    ref: "master",
    },
    codeMirrorConfig: {
    theme: "abcdef",
    mode: "python"
    },
    kernelOptions: {
    kernelName: "python3",
    path: ""
    }
}
</script>

    <!-- .js-show-sidebar shows sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      



<nav id="js-sidebar" class="c-textbook__sidebar">
  <a href="https://mitpress.mit.edu/books/case-studies-neural-data-analysis" target="_blank" rel="noopener noreferrer"><img src="/Case-Studies-Python/images/logo/logo.png" class="textbook_logo" id="sidebar-logo" alt="textbook logo" data-turbolinks-permanent></a>
  <h2 class="c-sidebar__title">Case Studies in Neural Data Analysis</h2>
  <ul class="c-sidebar__chapters">
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/intro">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/intro.html">
          
          Home
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      
        <li class="c-sidebar__divider">
        
      
      
        <li><h2 class="c-sidebar__title">Contents</h2></li>
        
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/01/introduction-to-python">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/01/introduction-to-python.html">
          
            1.
          
          Introduction to Python
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/02/the-event-related-potential">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/02/the-event-related-potential.html">
          
            2.
          
          The Event-Related Potential
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/03/the-power-spectrum-part-1">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/03/the-power-spectrum-part-1.html">
          
            3.
          
          The Power Spectrum (Part 1)
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/04/ecog-rhythms">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/04/ecog-rhythms.html">
          
            4.
          
          The Power Spectrum (Part 2)
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/05/the-cross-covariance-and-coherence">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/05/the-cross-covariance-and-coherence.html">
          
            5.
          
          The Cross Covariance and Coherence
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/06/filtering-scalp-eeg">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/06/filtering-scalp-eeg.html">
          
            6.
          
          Filtering Field Data
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/07/cross-frequency-coupling">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/07/cross-frequency-coupling.html">
          
            7.
          
          Cross Frequency Coupling
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/08/basic-visualizations-and-descriptive-statistics-of-spike-train-data">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/08/basic-visualizations-and-descriptive-statistics-of-spike-train-data.html">
          
            8.
          
          Basic Visualizations and Descriptive Statistics of Spike Train Data
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/09/point-process-glms">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/09/point-process-glms.html">
          
            9.
          
          Modeling place Fields with Point Process Generalized Linear Models
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/10/spiking-rhythms">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/10/spiking-rhythms.html">
          
            10.
          
          Analysis of Rhythmic Spiking in the Subthalamic Nucleus During a Movement Task
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/11/spike-field-coherence">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/11/spike-field-coherence.html">
          
            11.
          
          Analysis of Spike-Field Coherence
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      
        <li class="c-sidebar__divider">
        
      
      
        <li><h2 class="c-sidebar__title">Appendices</h2></li>
        
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/A01/backprop">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/A01/backprop.html">
          
            12.
          
          Backpropagation
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/A02/HH">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/A02/HH.html">
          
            13.
          
          Hodgkin Huxley Model
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/A03/LIF">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/A03/LIF.html">
          
            14.
          
          Integrate and Fire Model
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/A04/perceptron">
        <a class="c-sidebar__entry" href="/Case-Studies-Python/A04/perceptron.html">
          
            15.
          
          Training a Perceptron
        </a>
      </li>

      
      

      

      
      

      

      
    
  </ul>
  <p class="sidebar_footer">Powered by <a href="https://github.com/jupyter/jupyter-book" target="_blank" rel="noopener noreferrer">Jupyter Book</a></p>
</nav>

      
      <div class="c-topbar" id="top-navbar">
  <!-- We show the sidebar by default so we use .is-active -->
  <div class="c-topbar__buttons">
    <button id="js-sidebar-toggle" class="hamburger hamburger--arrowalt is-active">
      <span class="hamburger-box">
        <span class="hamburger-inner"></span>
      </span>
    </button>
    <div class="buttons">
<div class="download-buttons-dropdown">
    <button id="dropdown-button-trigger" class="interact-button"><img src="/Case-Studies-Python/assets/images/download-solid.svg" alt="Download"></button>
    <div class="download-buttons">
        
        <a id="interact-button-print"><button id="interact-button-download" class="interact-button">.pdf</button></a>
    </div>
</div>


</div>

  </div>
  <!-- Empty sidebar placeholder that we'll auto-fill with javascript -->
  <aside class="sidebar__right">
    <header><h4 class="nav__title">
<img src="/Case-Studies-Python/assets/images/list-solid.svg" alt="Search">   On this page</h4></header>
    <nav class="onthispage">
    </nav>
  </aside>
  <a href="/Case-Studies-Python/search.html" class="topbar-right-button" id="search-button">
    <img src="/Case-Studies-Python/assets/images/search-solid.svg" alt="Search">
  </a>
</div>

      <main class="c-textbook__page" tabindex="-1">
            <div class="c-textbook__content" id="textbook_content">
              <p><a id="introduction"></a></p>
<h1 id="the-event-related-potential-for-the-practicing-neuroscientist">The Event-Related Potential <em>for the practicing neuroscientist</em>
</h1>

<p>+++</p>

<div class="question">

  <p><em><strong>Synopsis</strong></em></p>

  <p><strong>Data:</strong> 1 s of scalp EEG data sampled at 500 Hz during 1,000 trials in two conditions.</p>

  <p><strong>Goal:</strong> Characterize the response of the EEG in the two conditions.</p>

  <p><strong>Tools:</strong> Visualization, event-related potential, confidence intervals, bootstrapping.</p>
</div>

<p>+++</p>

<ul>
  <li><a href="#background">Background</a></li>
  <li><a href="#case-study-data">Case Study Data</a></li>
  <li>
<a href="#data-analysis">Data Analysis</a>
    <ul>
      <li><a href="#visual-inspection">Visual Inspection</a></li>
      <li><a href="#plotting-the-erp">Plotting the ERP</a></li>
      <li><a href="#cis-m1">Confidence Intervals for the ERP (Method 1)</a></li>
      <li><a href="#comparing-erps">Comparing ERPs</a></li>
      <li><a href="#cis-m2">Confidence Intervals for the ERP (Method 2)</a></li>
      <li><a href="#bootstrap">A Bootstrap Test to Compare ERPs</a></li>
    </ul>
  </li>
  <li><a href="#summary">Summary</a></li>
</ul>

<p>+++</p>

<p>Before we start any computations, let’s import some modules and functions that we will use throughout the chapter. A module can be imported any time, but there are a few things that we know we will need straight off the bat. For clarity, it is best practice to import packages at the beginning.</p>

<p>You will see that we have imported <code class="language-plaintext highlighter-rouge">matlab.pyplot</code> and can call any functions in the module with <code class="language-plaintext highlighter-rouge">plt.f()</code>, where <code class="language-plaintext highlighter-rouge">f</code> should be replaced with the name of the desired function. Hence, if we want to plot something, we would call <code class="language-plaintext highlighter-rouge">plt.plot()</code>. However, we will use that function so often that it will be convenient to import <code class="language-plaintext highlighter-rouge">plot()</code> directly without typing <code class="language-plaintext highlighter-rouge">plt</code> first.</p>

<p>```{code-cell} ipython3
from scipy.io import loadmat       # Import function to read data.
from IPython.lib.display import YouTubeVideo  # Enable YouTube videos
import numpy as np                 # Import numpy for computations
import matplotlib.pyplot as plt    # Import a useful plotting package, 
from matplotlib.pyplot import plot, xlabel, ylabel, title, show, subplots, savefig
                                   # … and a few specific functions that are used often</p>
<h1 id="-make-the-plots-inline">… make the plots “inline”.</h1>
<p>%matplotlib inline</p>

<h1 id="tools-for-this-chapter">Tools for this chapter</h1>
<p>from matplotlib.pyplot import imshow, colorbar, hlines, vlines
from numpy import sqrt
from numpy.random import randint</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
## On-ramp: computing the event-related potential in Python

We begin this module with an "*on-ramp*" to analysis. The purpose of this on-ramp is to introduce you immediately to a core concept in this module: how to compute an event-related potential with error bars in Python. You may not understand all aspects of the program here, but that's not the point. Instead, the purpose of this on-ramp is to  illustrate what *can* be done. Our advice is to simply run the code below and see what happens ...

```{code-cell} ipython3
data = loadmat('EEG-1.mat')  # Load the data,
EEGa = data['EEGa']  # ... and get the EEG from one condition,
t = data['t'][0]   # ... and a time axis,
ntrials = len(EEGa)  # ... and compute the number of trials.

mn = EEGa.mean(0)  # Compute the mean signal across trials (the ERP)
sd = EEGa.std(0)  # Compute the std of the signal across trials
sdmn = sd / sqrt(ntrials)  # Compute the std of the mean

plt.figure(figsize=(12,3))  # Resize the figure
plot(t, mn, 'k', lw=3)  # Plot the ERP of condition A
plot(t, mn + 2 * sdmn, 'k:', lw=1)  # ... and include the upper CI
plot(t, mn - 2 * sdmn, 'k:', lw=1)  # ... and the lower CI
xlabel('Time [s]')  # Label the axes
ylabel('Voltage [$\mu$ V]')
title('ERP of condition A')  # ... provide a useful title
show()  # ... and show the plot
</code></pre></div></div>

<div class="question">

  <p><strong>Q:</strong> Try to read the code above. Can you see how it loads data, computes the event-related potential and error, and then plots the results?</p>

  <p><strong>A:</strong> If you’ve never computed an event-related potential before, that’s an especially difficult question. Please continue on to learn this <strong>and more</strong>!</p>
</div>

<p>+++</p>

<h2 id="background-">Background <a class="anchor" id="background"></a>
</h2>

<p>```{code-cell} ipython3
YouTubeVideo(‘Cy_BF7smAkk’)</p>
<h1 id="no-code">NO CODE</h1>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Voltage recordings from the scalp surface - the electroencephalogram or EEG - provide a powerful window into brain voltage activity.  Some of the earliest human EEG recording occurred in 1924, when [Dr. Hans Berger](https://en.wikipedia.org/wiki/Hans_Berger) made a remarkable discovery:  the EEG of a human subject at rest with eyes closed exhibits rhythmic activity, an approximately 10 Hz oscillation he labeled the alpha rhythm.  Although now studied for nearly 100 years, the definitive functional role (if any) of the alpha rhythm remains unknown.  Since then, many other EEG rhythms have been detected and labelled (typically with Greek letters) and the analysis of EEG rhythms remains [an active area of research](https://global.oup.com/academic/product/rhythms-of-the-brain-9780199828234). 

Compared to other modalities for measuring brain activity, the EEG possesses both advantages and disadvantages.  Perhaps the most important advantages are:

1. The EEG is non-invasive, and
2. The EEG permits a high temporal resolution (on the order of milliseconds).

However, the EEG measure also suffers from significant disadvantages, the most devastating being the poor spatial resolution;  a single scalp electrode detects the summed activity from approximately 10 cm&lt;sup&gt;2&lt;/sup&gt; of cortex.

In this chapter, we consider EEG data recorded from a single scalp electrode.  We will analyze these data to determine what (if any) activity is evoked following two different types of stimuli presented to a human subject.  In doing so, we will use Python, and see how this powerful tool can help us understand these time series data.  We begin with a brief description of the EEG data.

+++

[Return to top](#introduction)

+++

## Case Study: an EEG ERP task &lt;a class="anchor" id="case-study-data"&gt;&lt;a/&gt;

```{code-cell} ipython3
YouTubeVideo('q2-DjvPRaNA')
# NO CODE
</code></pre></div></div>

<p>An undergraduate student volunteers to participate in a psychology study at his university. In this study, EEG electrodes (sampling rate 500 Hz, i.e., 500 samples per second) are placed on the student’s scalp, and he is seated in a comfortable chair in a dark, electrically isolated room.  The student is instructed to place headphones over his ears and listen to a series of repeated sounds.  The sounds consist of two tones - either a high pitch tone or a low pitch tone.  A single tone is presented once every few seconds, and the student responds with a button press to the low pitch tone.  The tone presentation is repeated to collect the EEG response to numerous presentations of the two tones, as illustrated here:</p>

<p><img src="imgs/2-1.png"></p>

<p>In this cartoon illustration of the EEG experiment, the EEG electrodes are placed on the scalp surface of a human subject (left).  The EEG activity (blue) is recorded as a function of time during presentation of high pitch tones (black) and low pitch tones (orange).</p>

<p>Our collaborator leading this research study has agreed to provide us with EEG data recorded at a single electrode for 1000 presentations of the high pitch tone, and 1000 presentations of the low pitch tone.  In each presentation - or “trial” - she provides us with 1 s of EEG data, such that the tone occurs at 0.25 s into the trial.  She asks us to analyze these data to determine whether the EEG signal differs following the two tone presentations.</p>

<p>+++</p>

<p><a href="#introduction">Return to top</a></p>

<p>+++</p>

<h2 id="data-analysis-">Data Analysis <a id="data-analysis"></a>
</h2>

<p>+++</p>

<p>Our first step is to load the data into Python.  To do so, we use the function <code class="language-plaintext highlighter-rouge">loadmat()</code> from the <code class="language-plaintext highlighter-rouge">scipy.io</code> module as follows:</p>

<p>```{code-cell} ipython3
from scipy.io import loadmat       # Import function to read data.
data = loadmat(‘EEG-1.mat’)</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
To understand the outcome of issuing this command, let's examine the variable `data` now present in the workspace.  This variable is a *dictionary* variable (to see this, execute `type(data)`). To see the *keys* of a dictionary, use the `keys()` method.

```{code-cell} ipython3
data.keys()
</code></pre></div></div>

<p>The keys that start and end with two underscores ( <code class="language-plaintext highlighter-rouge">__</code> ) are private and contain information about the MATLAB file; we will not need those keys here. The variables that we are interested in here are <code class="language-plaintext highlighter-rouge">EEGa</code>, <code class="language-plaintext highlighter-rouge">EEGb</code>, and <code class="language-plaintext highlighter-rouge">t</code>. These correspond to the EEG data recorded in the two conditions (i.e., <code class="language-plaintext highlighter-rouge">EEGa</code> to condition A and <code class="language-plaintext highlighter-rouge">EEGb</code> to condition B) as well as a time axis (<code class="language-plaintext highlighter-rouge">t</code>). Let’s extract these variables from the <code class="language-plaintext highlighter-rouge">data</code> dictionary.</p>

<p>```{code-cell} ipython3
EEGa = data[‘EEGa’]
EEGb = data[‘EEGb’]
t = data[‘t’][0]</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
You may notice that we specified index zero when we imported the variable `t`. This is because `t` is a vector (one-dimensional) rather than an array (multi-dimensional). The default behavior of `loadmat()` is to extract variables as ndarray types (to see this, execute `type(EEGa)`). Specifically, if we don't tell Python to import the [zeroth](https://en.wikipedia.org/wiki/Zero-based_numbering) (row) element of `data['t']` then `t` will have shape (1, 500), rather than (500,). There may be cases where this arrangement is preferred, but best practice is to convert the variable to a one-diminsional vector.

```{code-cell} ipython3
print(data['t'].shape)
print(t.shape)
print(len(data['t']))
print(len(data['t'][0]))
</code></pre></div></div>

<div class="python-note">

  <p>In general, a single underscore at the beginning of a variable, function or method indicates that this object should be treated as <em>private</em>. Double underscores often indicate that Python will interpret this object with some special instructions. In both cases, for what we are doing, we can usually ignore an object that starts with an underscore.</p>
</div>

<p>+++</p>

<p>Let’s use the <code class="language-plaintext highlighter-rouge">whos</code> command to get some more information about the variables.</p>

<p>```{code-cell} ipython3
whos</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;div class="python-note"&gt;
    
We could also have used `EEGa.shape` to find out the dimensions of the variable `EEGa`.
&lt;/div&gt;

+++

In the *Data/Info* column we see *1000x500* for `EEGa` and `EEGb`.  Both variables are matrices with 1000 rows and 500 columns.  Our collaborator tells us that:
- each row corresponds to a separate trial, and
- each column to a point in time.

So there are 1000 total trials, each consisting of 500 time points.  As a matter of convenience, we define a new variable to record the number of trials:

```{code-cell} ipython3
ntrials = EEGa.shape[0]  # len(EEGa) would give the same result
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">shape</code> property of an array is a <em>tuple</em> that indicates the size of each dimension. Adding <code class="language-plaintext highlighter-rouge">[0]</code> at the end tells Python to give us only the first value in the tuple. Recall that Python indexing starts at 0. This variable will be useful later, as we’ll see. In fact, we can assign two variables at the same time:</p>

<p>```{code-cell} ipython3
ntrials, nsamples = EEGa.shape</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
With this syntax:
- we assign the variable `ntrials` to the value `EEGa.shape[0]`, which is the number of rows.
- we assign the variable `nsamples` to the value `EEGa.shape[1]`, which is the number of columns.

+++

&lt;div class="question"&gt;

**Q.** Determine the size of the variable `EEGb`. How many rows and columns does it possess? Which dimension corresponds to trials and which corresponds to time?
&lt;/div&gt;

+++

&lt;div class="python-note"&gt;
    
A *tuple* is another data structure in Python that is similar to an array or a list because it usually contains more than one element. Python treats each of these structures slightly differently, however. One of the most challenging things about starting with Python is learning to understand the different data structures. Here, we will mainly work with arrays, which are good for holding multidimensional data. If you are curious and want to know more about data structures, there is a very concise description &lt;a href="http://thomas-cokelaer.info/tutorials/python/data_structures.html"&gt;here&lt;/a&gt; to get you started.
&lt;/div&gt;

+++

[Return to top](#introduction)

+++

### Visual Inspection &lt;a id="visual-inspection"&gt;&lt;/a&gt;

```{code-cell} ipython3
YouTubeVideo('uSjd41G-yNY')
# NO CODE
</code></pre></div></div>

<p>Both <code class="language-plaintext highlighter-rouge">EEGb</code> and <code class="language-plaintext highlighter-rouge">EEGa</code> are complicated variables that contain many elements. To understand these data, we might attempt to read the values contained in each element. For example, we can print out the EEG data for the first trial of condition A</p>

<p>```{code-cell} ipython3
print( EEGa[0] )  # EEGa[0, :] is equivalent to EEGa[0]</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
In this command, we index the first row of the matrix `EEGa` and print out all columns (corresponding to all moments of time).

+++

&lt;div class="question"&gt;

**Q.** Upon issuing this command what do you find? Does the printout help you understand these data?

**A.** You should observe a list of 500 numbers that begins 

    `-1.85909632e-01   4.49876010e-01   1.06070801e+00  -4.71265246e-01   1.68669327e+00   9.38221338e-01 ...`
    
We might conclude that these numbers exhibit variability (i.e., the values are both positive and negative), but examining the data in this way is not particularly useful. For example, determining trends in the behavior (such as intervals of repeated activity) through inspection of these printed numbers alone is extremely difficult.
&lt;/div&gt;

```{code-cell} ipython3
YouTubeVideo('9qx29zDxcAc')
# NO CODE
</code></pre></div></div>

<p>Printing out the data to the screen is <strong>not useful</strong> in this case. How else can we deepen our understanding of these data? Let’s make a plot:
<a id="fig:2"></a></p>

<p>```{code-cell} ipython3
plot(EEGa[0])                   # Plot the data from condition A, trial 1.
savefig(‘imgs/2-2a’)
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Visualizing the data in this way, we immediately notice many features. First, let’s consider the axes. The horizontal axis extends from 0 to (nearly) 500. This corresponds to the 500 columns in the variable `EEGa`. While this visualization is useful, it would be more informative to plot the EEG data as a function of time rather than indices. Fortunately, we possess a variable `t` in the workspace that corresponds to the time axis. Determining the size of the variable `t`, we find it is a vector with 1 row and 500 columns. Each column corresponds to a point in time.

+++

&lt;div class="question"&gt;
    
**Q.** Plot the variable `t`. What is its range? 
&lt;/div&gt;

+++

The variable `t` corresponds to the 1 s of EEG data recorded in each trial. We can also use the variable `t` to determine the sampling interval,

```{code-cell} ipython3
dt = t[1] - t[0]  # Determine the sampling interval
</code></pre></div></div>

<p>The new variable <code class="language-plaintext highlighter-rouge">dt</code> corresponds to the time between samples.</p>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> What is the value of <code class="language-plaintext highlighter-rouge">dt</code>? We were told by our collaborator that the sampling frequency is 500 Hz. Is the value of <code class="language-plaintext highlighter-rouge">dt</code> consistent with this sampling frequency?</p>

  <p><strong>A.</strong> Yes, it is consistent. Using the command <code class="language-plaintext highlighter-rouge">print(dt)</code>, we find that <code class="language-plaintext highlighter-rouge">dt</code> is 0.002 s, or 2 ms. The sampling frequency of 500 Hz corresponds to one sample of the EEG data every 1/(500 Hz) = 2 ms. If the two were not consistent, we would return to our collaborator and figure out what has gone wrong. In general, it’s useful to ask such questions along the way to make sure we understand the formatting of the data and catch any potentially serious misunderstandings early in the analysis.</p>
</div>

<p>+++</p>

<div id="singleTrial">

  <p>We can now combine the time axis with the EEG data to make a more complete plot. Let’s also label the axes and give the plot a title.</p>

</div>

<p>```{code-cell} ipython3
plot(t, EEGa[0])                     # Plot condition A, trial 1 data vs t.
xlabel(‘Time [s]’)                   # Label the x-axis as time.
ylabel(‘Voltage [$\mu$ V]’)          # Label the y-axis as voltage.
title(‘EEG data from condition A, Trial 1’)  # Add a title</p>

<h1 id="add-a-vertical-line-to-indicate-the-stimulus-time">Add a vertical line to indicate the stimulus time</h1>
<p>plot([0.25, 0.25], [-4,4], ‘k’, lw=2)
savefig(‘imgs/2-2b’)
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
This plot provides a nice summary of the data in the first trial of condition A. Visual inspection of the plot suggests that these data exhibit complicated activity. We know from our collaborator that the stimulus occurs at time 0.25 s in each trial. Note how we indicated this time as a vertical line in the plot above. This command includes additional options that make the line black (`'k'`) and a bit wider (`lw=2`).

+++

&lt;div class="question"&gt;
    
**Q.** What else, if anything, can you say about the single trial of EEG data plotted above? Does the visual inspection reveal any particular change in the EEG activity following the stimulus presentation?
&lt;/div&gt;

+++

So far we have visualized only the data from condition A. Because we are interested in whether the EEG behaves differently in the two conditions, visualizing both conditions simultaneously would be of use. We can do this as follows:
&lt;a id="fig:3"&gt;&lt;/a&gt;

```{code-cell} ipython3
plt.figure(figsize=(12, 3))     # Resize the figure to make it easier to see
plot(t,EEGa[0])                 # Plot condition A, trial 1, data vs t,
plot(t,EEGb[0], 'r')            # ... and the data from condition B, trial 1,
xlabel('Time [s]')              # Label the x-axis as time.
ylabel('Voltage [\mu V]')       # Label the y-axis as voltage.
title('EEG data from conditions A (blue) and B (red), Trial 1') # And give it a title.
savefig('imgs/2-3')
show()
</code></pre></div></div>

<div class="python-note">

  <p>Note that because we did not import the function <code class="language-plaintext highlighter-rouge">figure()</code> directly, we need to include the prefix <code class="language-plaintext highlighter-rouge">plt</code>.</p>

</div>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> Compare the voltage traces from the first trial of conditions A and B as plotted above. What similarities and differences do you observe?</p>
</div>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> The analysis has so far focused only on the first trial. Repeat this visual inspection of the data for different trials. What do you find? What similarities and differences exist between the two conditions across trials?</p>
</div>

<p>```{code-cell} ipython3
YouTubeVideo(‘nandZ5aaRaQ’)</p>
<h1 id="no-code-1">NO CODE</h1>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
These techniques allow us to visualize the data one trial at a time. That is useful but can be time consuming, especially for a large number of trials. For the EEG data of interest here, each condition contains 1,000 trials, and to visualize each trial separately could require 2,000 plots. We can certainly create 2,000 plots, but the subsequent visual inspection would be time consuming and difficult. Fortunately, a more efficient visualization approach exists: we can display the entire structure of the data across both time and trials as an image:
&lt;a id="fig:4"&gt;&lt;/a&gt;

```{code-cell} ipython3
imshow(EEGa,                                   # Image the data from condition A.
           cmap='BuPu',                            # ... set the colormap (optional)
           extent=[t[0], t[-1], 1, ntrials],       # ... set axis limits (t[-1] represents the last element of t)
           aspect='auto',                          # ... set aspect ratio 
           origin='lower')                         # ... put origin in lower left corner
xlabel('Time[s]')                              # Label the axes
ylabel('Trial #')
colorbar()                                     # Show voltage to color mapping
vlines(0.25, 1, 1000, 'k', lw=2)       # Indicate stimulus onset with line
savefig('imgs/2-4')
show()
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">imshow</code> command allows us to visualize the entire matrix <code class="language-plaintext highlighter-rouge">EEGa</code> as a function of trial number and time. Each row corresponds to a single trial of duration 1 s, and the color indicates the voltage, with darker (lighter) colors indicating higher (lower) voltages. This plot also indicates the time of stimulus presentation with a vertical black line as a cue to assist visual inspection.</p>

<p>+++</p>

<div class="python-note">

  <p>We have used the <em>BuPu</em> color map for the plot above. There are many other options; use <code class="language-plaintext highlighter-rouge">plt.colormaps?</code> for details.</p>
</div>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong>
Upon close inspection of the figure above, what response, if any, do you observe following the stimulus presentation? (Look <em>really</em> carefully.) Repeat this visualization and analysis for <code class="language-plaintext highlighter-rouge">EEGb</code>. How do the two conditions compare?</p>
</div>

<p>+++</p>

<p><a href="#introduction">Return to top</a></p>

<p>+++</p>

<h3 id="plotting-the-erp-">Plotting the ERP <a id="plotting-the-erp"></a>
</h3>

<p>```{code-cell} ipython3
YouTubeVideo(‘kPr2GLSKLJg’)</p>
<h1 id="no-code-2">NO CODE</h1>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
Visual inspection of the EEG data has so far come up empty. The EEG traces appear noisy or perhaps rhythmic, but from visual inspection of the individual trials it’s difficult to make a decisive conclusion of underlying structure&lt;span class="sup"&gt;fig&lt;img src="imgs/2-2b.png"&gt;&lt;/span&gt;. To further investigate the activity in these data, we compute the **event-related potential** (ERP).

To compute the ERP, we first assume that each trial evokes an instantiation of the same underlying brain process. So, in this case, we assume that the same brain response is evoked 1,000 times (once for each trial) for each condition. However, the evoked response due to the stimulus is small and hidden in the EEG signal by other ongoing activity unrelated to the stimulus (e.g., daydreaming, thoughts of dinner, thoughts of homework). Therefore, to tease out the weak evoked effect, **we average the EEG responses across trials**. Ideally, EEG activity unrelated to the stimulus will cancel out in the average, while EEG activity evoked by the stimulus will sum constructively. The procedure to perform and display this averaging can be done in Python as follows:
&lt;a id="fig:5"&gt;&lt;/a&gt;

```{code-cell} ipython3
plot(t, EEGa.mean(0))  # Plot the ERP of condition A
xlabel('Time [s]')           # Label the axes
ylabel('Voltage [$\mu V$]')
title('ERP of condition A')  # ... provide a title
savefig('imgs/2-5')
show()                       # ... and show the plot
</code></pre></div></div>

<p>In the first line, we compute the mean of <code class="language-plaintext highlighter-rouge">EEGa</code> using the method <code class="language-plaintext highlighter-rouge">mean()</code> (see the documentation for this function <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html" target="_blank" rel="noopener noreferrer">here</a>). The default behavior is to compute the mean of all elements of the array. By calling <code class="language-plaintext highlighter-rouge">EEG.mean(0)</code>, we compute the mean along the zeroth dimension. The result is the ERP for condition A.</p>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> Consider the ERP for condition A plotted above. Update this figure to include a vertical line at the location of the stimulus, and the ERP for condition B. How, if at all, do the ERPs for Conditions A and B differ?</p>

</div>

<p>+++</p>

<p>The ERP of condition A shows the mean voltage across trials at each moment in time. Visual inspection suggests that before stimulus presentation (i.e., times 0 s to 0.25 s) the EEG fluctuates around zero. Then, after stimulus presentation, the ERP increases and decreases substantially above and below zero. Which, if any, of these deviations following stimulation are significant? To address this, we make use of the trial structure of the EEG data to compute confidence bounds for the ERP. We do so in two ways.</p>

<p>+++</p>

<p><a href="#introduction">Return to top</a></p>

<p>+++</p>

<h3 id="confidence-intervals-for-the-erp-method-1-">Confidence Intervals for the ERP (Method 1) <a id="cis-m1"></a>
</h3>

<p>```{code-cell} ipython3
YouTubeVideo(‘pXCJbyrw8Ug’)</p>
<h1 id="no-code-3">NO CODE</h1>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
To compute the ERP we average the EEG data across many trials. Because of this, we may make use of a powerful theorem in statistics—the [*central limit theorem*](https://en.wikipedia.org/wiki/Central_limit_theorem) (CLT)—to include approximate confidence bounds in the ERP figure. Briefly, this theorem states that the mean of a sufficiently large number of independent random variables, each with finite mean and variance, will be approximately [normally distributed](https://en.wikipedia.org/wiki/Normal_distribution). Remember that the ERP at each moment in time is the sum of EEG activity across trials (then scaled by a constant, the number of trials). Let’s assume that the trials are independent (i.e., one trial does not depend on any other trial). Let’s also assume that the EEG data at each moment in time have finite mean and variance. With those assumptions, we have satisfied the CLT and may therefore conclude that the ERP at each moment in time is approximately normally distributed.

+++

&lt;div class="question"&gt;
    
**Q.** To use the CLT, we make two assumptions about the EEG data. Are these assumptions reasonable?

**A.** We assume that the EEG data are independent across trials. This assumption may fail if, for example, the activity in one trial influences the activity in the next trial. We also assume that the EEG data are “well-behaved” (i.e., have finite mean and variance). That is a reasonable assumption for physical data we observe from the brain; we expect the EEG data to always remain finite and not diverge to plus or minus infinity.

&lt;/div&gt;

+++

This conclusion—that the ERP at each moment in time is approximately normally distributed—is useful because the normal distribution (also known as the Gaussian distribution or bell curve) possesses many convenient properties. First, a normal distribution is relatively simple; it can be completely specified with two parameters: the mean value and the standard deviation. Second, 95% of the values drawn from a normal distribution lie within approximately two standard deviations of the mean.

+++

&lt;img src="imgs/gaussian.png" alt="Example Gaussian" style="width:40%; max-width:300px;"/&gt;

+++

Here's a plot of the canonical normal distribution showing the mean (dotted vertical line) and standard deviation (blue). Ninety-five percent of values lie within the interval indicated by the red bar.

+++

Therefore, to construct a 95% confidence interval for the ERP, we need to determine the mean and standard deviation of the mean across trials at each point in time. To compute the mean in Python is easy:

```{code-cell} ipython3
mn = EEGa.mean(0)  # Compute the mean across trials (the ERP)
</code></pre></div></div>

<div class="python-note">

  <p>Note that when we refer to the <em>mean</em> here we could instead write <em>sample mean</em> because we use the observed data to estimate the theoretical mean that we would see if we kept repeating this experiment. This distinction is not essential to our goals here, but it is important when talking to your statistics-minded colleagues. Throughout the book, we omit the term sample when referring to sample means, variances, covariances, and so forth, unless this distinction is essential to the discussion.</p>

</div>

<p>+++</p>

<p>We again note that the second input to the <code class="language-plaintext highlighter-rouge">mean</code> function specifies the dimension in which we compute the mean, in this case, across the first dimension of the variable <code class="language-plaintext highlighter-rouge">EEGa</code> corresponding to the trials. To compute the standard deviation of the mean, we start by computing the standard deviation of the data:</p>

<p>```{code-cell} ipython3
sd = EEGa.std(0)  # Compute the std across trials</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
But we’re not interested in the standard deviation of the EEG data across trials; instead, we’re interested in the standard deviation *of the estimate of the mean*. To calculate the standard deviation of the mean, we divide the standard deviation of the data by the square root of the number of trials (i.e., the number of terms used to compute the mean). In Python,

```{code-cell} ipython3
sdmn = sd / sqrt(ntrials)  # Compute the std of the mean
</code></pre></div></div>

<p>Now, having found the mean (<code class="language-plaintext highlighter-rouge">mn</code>) and the standard deviation of the mean (<code class="language-plaintext highlighter-rouge">sdmn</code>), we can compute a 95% confidence interval for the ERP. We again exploit the observation, based on the central limit theorem, that the ERP is normally distributed at each instant of time. With these calculations, the following code plots the ERP and the 95% confidence interval:</p>

<p>```{code-cell} ipython3
fig, ax = subplots(figsize=(12, 3))     # Save the axes for use in later cells and resize the figure
ax.plot(t, mn, ‘k’, lw=3)              # Plot the ERP of condition A
ax.plot(t, mn + 2 * sdmn, ‘k:’, lw=1)  # … and include the upper CI
ax.plot(t, mn - 2 * sdmn, ‘k:’, lw=1)  # … and the lower CI
xlabel(‘Time [s]’)                     # Label the axes
ylabel(‘Voltage [$\mu$ V]’)
title(‘ERP of condition A’)            # … provide a useful title
fig                                    # … and show the plot
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
The ERP computed with confidence intervals allows us to ask specific questions about the data. For example, does the ERP ever differ significantly from zero? To answer this, we look for intervals of the ERP for which the confidence intervals do not include zero. To aid visual inspection, we add to the ERP plot a horizontal line at 0: &lt;a id="plt:erpA-m1"&gt;&lt;/a&gt;

+++

&lt;div class="python-note"&gt;
    
A good rule of thumb when you are programming is that you should not be rewriting (or copy-pasting) code over and over again. Instead, you should write a function that you can call whenever you need the action that you keep repeating. At this point, we have resized the plots and labeled the axes the same way several times so we should fix the default plot size and write a function that automates the labeling so that next time we make a plot, we don't need to rewrite the same code again.
&lt;/div&gt;

```{code-cell} ipython3
# Change the default figure size
from matplotlib import rcParams
rcParams['figure.figsize'] = (12, 3)

# Create a function to label plots
def labelPlot(title_string="Title"):
    '''
    A function that labels the x-axis as 'Time [s]' and
    the y-axis as 'Voltage [$\mu V$]'. 
    Arguments:
        title_string:  string variable to be used as
                       the plot title (default: 'Title')
                       
    '''
    xlabel('Time [s]')           # x-axis is time
    ylabel('Voltage [$/mu V$]')  # y-axis is voltage
    title(title_string)          # use the input here
    plt.autoscale(tight=True)    # no white-space in plot
</code></pre></div></div>

<div class="question">

  <p><strong>Q.</strong> How would you write a function to compute the ERP and confidence bounds of a dataset?</p>

</div>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> What do you think the following code will do?</p>

  <div class="language-plaintext highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>   `ax.hlines(0, t[0], t[-1])`
</code></pre></div>  </div>

  <p>Try it out.</p>

</div>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> What is the role of the method function <code class="language-plaintext highlighter-rouge">hlines()</code> in this code? <em>Hint</em>: If you have not encountered this function before, look it up in the Documentation.</p>

</div>

<p>```{code-cell} ipython3
ax.hlines(0, t[0], t[-1])
fig.savefig(‘imgs/2-7’)
fig</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
In the figure above, the thick line indicates the ERP for Condition A (i.e., the mean of the EEG across trials) while the thin dotted lines indicate the 95% confidence intervals.

+++

We find three time intervals at which the confidence intervals of the ERP do not include zero: near 0.27 s, near 0.37 s, and near 0.47 s. These results suggest that for an interval of time following the stimulus presentation in condition A, the observed ERP is not a random fluctuation about zero but instead contains consistent structure across trials.

+++

&lt;div class="question"&gt;
    
**Q.** Construct the ERP with confidence intervals for condition B. As for condition A, you should find that before stimulus presentation the ERP fluctuates around zero. What intervals of time, if any, differ significantly from zero?
&lt;/div&gt;

+++

[Return to top](#introduction)

+++

### Comparing ERPs &lt;a class="anchor" id="comparing-erps"&gt;&lt;/a&gt;

+++

In the previous section, we implemented a procedure to compute confidence intervals for the ERPs in conditions A and B. To investigate *differences* between the ERPs in the two conditions, we can use a similar approach. To start, let’s plot the ERPs with confidence intervals for both conditions and attempt to identify periods for which the confidence intervals do not overlap (such intervals would correspond to significant differences between the responses of the two conditions).

```{code-cell} ipython3
from my_module import ERP  # A function written by the author to compute the ERP

erpA, ca_l, ca_h = ERP(data['EEGa'])  # Compute the ERP of condition A
erpB, cb_l, cb_h = ERP(data['EEGb'])  # ... and condition B

plot(t, ca_l, 'r:', t, ca_h, 'r:')  # Plot confidence bounds in back
plot(t, cb_l, 'b:', t, cb_h, 'b:')
plot(t, erpA, 'r', lw=3, label='condition A')  # ... and ERPs in front
plot(t, erpB, 'b', lw=3, label='condition B')

# Prettify
labelPlot('ERP of conditions A and B')
legend()
savefig('imgs/2-8a')
show()
</code></pre></div></div>

<div class="question">

  <p><strong>Q.</strong> In the cell above, the ERPs and confidence bounds are computed using a function written by the author. Can you write the code to make this plot yourself?</p>
</div>

<p>+++</p>

<p>As you can see, the plot of both ERPs is rather messy; it’s difficult to determine through visual inspection alone in which intervals the ERPs exhibit significant separation.</p>

<p>To facilitate further inspection of the data, we compute the difference between the ERPs in the two conditions. In the differenced signal, large deviations between the two conditions will appear as large differences from zero. To determine whether a deviation is significantly different from zero, we need to determine the confidence interval for the differenced ERP. This requires we propagate the standard deviation of the mean for both ERPs to the new differenced ERP. The propagated standard deviation of the mean at a fixed moment in time is computed as:</p>

<p><a id="eq:1"></a>
<script type="math/tex">\sigma = \sqrt{\frac{\sigma_A^2}{K} + \frac{\sigma_B^2}{K}}, \tag{1}</script></p>

<p>where $\sigma_A$ is the standard deviation of the data from condition A, $\sigma_B$ is the standard deviation of the data from condition B, and $K$ is the number of trials.</p>

<p>In Python we compute the differenced ERP and standard deviation of the mean of the difference as follows:
<a id="plt:differencedERP"></a></p>

<p>```{code-cell} ipython3
mnA = EEGa.mean(0)  # ERP of condition A
sdmnA = EEGa.std(0) / sqrt(ntrials)  # … and standard dev of mean</p>

<p>mnB = EEGb.mean(0)  # ERP of condition B
sdmnB = EEGb.std(0) / sqrt(ntrials)  # … and standard dev of mean</p>

<p>mnD = mnA - mnB  # the differenced ERP
sdmnD = sqrt(sdmnA ** 2 + sdmnB ** 2)  # … and its standard dev</p>

<p>plot(t, mnD, ‘k’, lw=3)  # plot the differenced ERP
plot(t, mnD + 2 * sdmnD, ‘k:’)  # … the upper CI
plot(t, mnD - 2 * sdmnD, ‘k:’)  # … and the lower CI
plot([0, 1], [0, 0], ‘b’)  # … and a horizontal line at 0
labelPlot(‘Differenced ERP’)  # label the plot
show()</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
In the code above we first compute the ERP and standard deviation of the mean for each condition. We then compute the differenced ERP (`mnD`) and the standard deviation of the mean of this difference (`sdmnD`)&lt;span href="#eq:1" class="sup"&gt;eq&lt;img src="imgs/eq1.png"&gt;&lt;/span&gt;. We note that `sdmnA`$= \sqrt{\sigma_A^2/K}$ and therefore `sdmnA**2` $= \sigma_A^2/K$, with similar expressions for condition B. We then plotted the resulting differenced ERP with 95% confidence intervals. The hope is that from this figure we can more easily identify significant differences between the two conditions.

+++

&lt;div class="question"&gt;
    
**Q:** Examine the plot of the differenced ERP. In what intervals of time do the EEG responses in the two conditions significantly differ?
&lt;/div&gt;

+++

[Return to top](#introduction)

+++

### Confidence Intervals for the ERP (Method 2) &lt;a id="cis-m2"&gt;&lt;/a&gt;

```{code-cell} ipython3
YouTubeVideo('vVXH4XsPFEs')
# NO CODE
</code></pre></div></div>

<p>So far we have computed confidence intervals for the ERPs by relying on the central limit theorem and approximating the average voltage values at each point in time as normally distributed. That’s a completely reasonable approach. And because the normal distribution is so well-behaved, it’s easy to compute the 95% confidence intervals. An alternative approach to generate confidence intervals is through a <strong>bootstrap</strong> procedure. Bootstrapping is a resampling method that allows us to estimate the sampling distribution of many different statistics. In this chapter, we implement a <em>nonparametric bootstrap</em> (see note). To do so, we generate new <em>pseudodata</em> from the observed EEG data. We begin by using a bootstrapping procedure to create confidence intervals for the ERPs observed in each condition.</p>

<p>+++</p>

<div class="math-note">

  <p><strong>A note on the nonparametric bootstrap.</strong> Briefly, there is strong theoretical justification for the nonparametric bootstrap. The fundamental idea is that resampling the data with replacement is equivalent to sampling new pseudodata from the empirical cumulative distribution function (eCDF) of the observed data. For a large sample of independent, identically distributed random variables, the distribution of the pseudodata generated from the eCDF will be close to the true distribution of the data. Note the important caveat that the variables are independent, identically distributed; this assumption fails in many cases, such as for time series. Here, we assume that each trial is drawn independently from the same distribution (i.e., the trials are independent, identically distributed variables).</p>
</div>

<p>+++</p>

<p>We implement the bootstrapping procedure to compute pointwise confidence intervals. By pointwise we mean that the confidence intervals are computed separately for each point in time, and interactions across time are not considered. The prescription for the bootstrapping procedure follows four steps:</p>

<ol>
  <li>Sample with replacement 1,000 trials of the EEG data from condition A.</li>
  <li>Average these 1,000 trials to create a resampled ERP.</li>
  <li>Repeat these two steps 3,000 times to create a distribution of ERPs.</li>
  <li>For each time point, identify the values greater than 2.5% and less than 97.5% of all 3,000 values. This range determines the 95% confidence interval for the ERP for that time point.</li>
</ol>

<p>Let’s now implement each step in Python.</p>

<p>```{code-cell} ipython3
YouTubeVideo(‘mqDEJyW_z4c’)</p>
<h1 id="no-code-4">NO CODE</h1>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
**Step 1.** In step 1 we must sample with replacement from the EEG data. To visualize this procedure, imagine placing 1,000 marbles in an opaque bag. Each marble is assigned a unique integer value from 1 to 1,000. Now, reach your hand into the bag, grab a marble, record its number, and replace the marble in the bag. We assume that each marble is equally likely to be selected at each draw (i.e., there are no special features that allow some marbles to be drawn more often). Repeat this procedure 1,000 times to create a list of 1,000 integers. Notice that after recording the drawn marble’s number, we replace it in the bag. So, we could potentially draw the same marble 1,000 times, although that’s extremely unlikely. Performing this sampling with replacement procedure by hand would, of course, be extremely time consuming (e.g., who will paint integers on each marble?). Fortunately, Python provides a function to perform sampling with replacement:

```{code-cell} ipython3
# Draw 1000 integers with replacement from [0, 1000)
i = np.random.randint(0, ntrials, size=ntrials)
</code></pre></div></div>

<p>The first and second inputs to <code class="language-plaintext highlighter-rouge">randint()</code> specify the minimum and maximum integers to draw, respectively. Note that the low number is included in the set, but the high number is not. If only the upper bound is given, the lower bound is assumed to be zero (i.e., we can rewrite the above line as <code class="language-plaintext highlighter-rouge">np.random.randint(ntrials, size=ntrials)</code>). The last input indicats the number of samples to draw (as always, use <code class="language-plaintext highlighter-rouge">np.random.randint?</code> to find out more).</p>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> Examine the values of <code class="language-plaintext highlighter-rouge">i</code>. What values do you find?</p>
</div>

<p>+++</p>

<p>The result <code class="language-plaintext highlighter-rouge">i</code> provides a list of integers between 0 and 999. These values specify the trials to use in creating the resampled EEG. This resampled EEG will contain the same number of trials as the original EEG (i.e., 1,000 trials) but in a different order and with possibly repeated trials. For example, if the sampling with replacement procedure returns</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>i = [10, 941, 3, 400, 10, ...
</code></pre></div></div>

<p>then the first and fifth trials of the resampled EEG will equal the eleventh trial of the original EEG (remember that Python indices start at zero). We create the resampled EEG in Python as follows:</p>

<p>```{code-cell} ipython3
EEG0 = EEGa[i]  # Create the resampled EEG.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
In this code we use the variable `i` as the index to the rows of `EEGa`.

+++

&lt;div class="question"&gt;
    
**Q.** What is the `shape` of the new variable `EEG0`? Is this shape consistent with the original EEG datasets?
&lt;/div&gt;

+++

That completes step 1 of the resampling procedure.

```{code-cell} ipython3
YouTubeVideo('bUzuNojLUik')
# NO CODE
</code></pre></div></div>

<p><strong>Step 2.</strong> This step is easy: we create a resampled ERP from the resampled EEG data. Computing the resampled ERP requires only one line of code in Python:</p>

<p>```{code-cell} ipython3
ERP0 = EEG0.mean(0)  # Create the resampled ERP</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;div class="question"&gt;
    
**Q.** What is the difference between the resampled EEG and resampled ERP? Explain your answer in words.
&lt;/div&gt;

+++

&lt;div class="question"&gt;
    
**Q.** Plot the resampled ERP that we created. What does it look like?
&lt;/div&gt;

```{code-cell} ipython3
YouTubeVideo('feQk_vKloXk')
# NO CODE
</code></pre></div></div>

<p><strong>Step 3.</strong> In the first two steps of the resampling procedure we created a single resampled ERP. In step 3 we are instructed to repeat this procedure 3,000 times and create a distribution of ERPs. How can we do so? One potential solution is to cut and paste the code we developed over and over again, for example:</p>

<p>```{code-cell} ipython3
i = np.random.randint(ntrials, size=ntrials);  # Draw integers,
EEG1 = EEGa[i];  # … create resampled EEG,
ERP1 = EEG1.mean(0);  # … create resampled ERP.</p>

<p>i = np.random.randint(ntrials, size=ntrials);  # Draw integers,
EEG2 = EEGa[i];  # … create resampled EEG,
ERP2 = EEG2.mean(0);  # … create resampled ERP.</p>

<p>i = np.random.randint(ntrials, size=ntrials);  # Draw integers,
EEG3 = EEGa[i];  # … create resampled EEG,
ERP3 = EEG3.mean(0);  # … create resampled ERP.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
In these lines we have created three resampled ERPs, each with its own variable name. We could, of course, repeat this procedure and eventually define the variable `ERP3000`.

+++

&lt;div class="question"&gt;
    
**Q.** Is defining the resampled ERPs in this way a good idea?

**A.** No! We should let the computer execute this repeated procedure for us. If you find yourself cutting and pasting the same code over and over again, you're probably doing something inefficient, inelegant, and error-prone.
&lt;/div&gt;

+++

A better approach to create the 3,000 resampled ERPs is with a *for-loop*. We do so in Python with the `for` statement:

```{code-cell} ipython3
def bootstrapERP(EEGdata, size=None):  # Steps 1-2
    """ Calculate bootstrap ERP from data (array type)"""
    ntrials = len(EEGdata)  # Get the number of trials
    if size == None:  # Unless the size is specified,
        size = ntrials  # ... choose ntrials
    i = np.random.randint(ntrials, size=size)  # ... draw random trials,
    EEG0 = EEGdata[i]  # ... create resampled EEG,
    return EEG0.mean(0)  # ... return resampled ERP.

ERP0 = [bootstrapERP(EEGa) for _ in range(3000)]  # Step 3: Repeat 3000 times 
ERP0 = np.array(ERP0)  # ... and convert the result to an array
</code></pre></div></div>

<p>In the first line, we define a function that performs the calculations that we wish to repeat. In this case, the function performs steps 1 and 2 of the bootstrapping procedure. The last two lines call the function 3,000 times and convert the result from a <em>list</em> into an <em>array</em>. This completes step 3 of the bootstrapping procedure.</p>

<p>+++</p>

<div class="python-note">

  <p>Note that in the definition of <code class="language-plaintext highlighter-rouge">bootstrapERP</code>, we included an argument (<code class="language-plaintext highlighter-rouge">size</code>) that has a <em>default</em> value (<code class="language-plaintext highlighter-rouge">None</code>). This lets us assume that we want the resampled dataset to be the same size as the original, which is true for right now. Later, however, we will reuse this function but will not want the resampled data to be the same size as the original.</p>
</div>

<p>+++</p>

<div class="python-note">

  <p>In Python it is common to see for-loops written in the form</p>

  <div class="language-plaintext highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>`y = [f(x) for x in some_set]`
</code></pre></div>  </div>

  <p>This will return a <em>list</em> datatype, which is why we had to convert it to an array in the code above. We could also have written the loop in an alternative way:</p>

  <div class="language-plaintext highlighter-rouge">
<div class="highlight"><pre class="highlight"><code>`ERP0 = np.zeros((3000, EEGa.shape[1]))`

`for k in range(3000):`

`    ERP0[k, :] = bootstrapERP()`
</code></pre></div>  </div>

  <p>Note that it is good practice, but not required, to define a function that contains the code you wish to repeat, especially if you might use it again later. This minimizes rewrites, and if there is a mistake then you only need to make a correction in one place.</p>
</div>

<p>```{code-cell} ipython3
YouTubeVideo(‘NLc93QESVZs’)</p>
<h1 id="no-code-5">NO CODE</h1>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
**Step 4.** In this step of the bootstrapping procedure, we determine for each time point the values greater than 2.5% and less than 97.5% of all values. There are many ways to perform this operation in Python, perhaps the easiest being to sort from smallest to largest the 3,000 resampled ERP values at each time point. With the resampled values sorted in this way, we then find the resampled ERP value at index $0.025 \times 3000 = 75$ and $0.975 \times 3000 = 2925$. These indices correspond to the resampled ERP values greater than 2.5% of all values and greater than 97.5% of all values, respectively, and therefore define the lower and upper confidence intervals at each moment in time. We can compute both confidence intervals in Python, and (at last!) plot the ERP for condition A with confidence intervals computed using the bootstrapping procedure: &lt;a id="fig:1"&gt;&lt;/a&gt;

```{code-cell} ipython3
ERP0.sort(axis=0)  # Sort each column of the resampled ERP
N = len(ERP0)  # Define the number of samples
ciL = ERP0[int(0.025*N)]  # Determine the lower CI
ciU = ERP0[int(0.975*N)]  # ... and the upper CI
mnA = EEGa.mean(0)  # Determine the ERP for condition A
plot(t, mnA, 'k', lw=3)  # ... and plot it
plot(t, ciL, 'k:')  # ... and plot the lower CI
plot(t, ciU, 'k:')  # ... and the upper CI
hlines(0, 0, 1, 'b')  # plot a horizontal line at 0
                      # ... and label the axes
labelPlot('ERP of condition A with bootstrap confidence intervals')  # We define this function above!
</code></pre></div></div>

<p>We can use these results to identify, for example, intervals in which the ERP differs significantly from zero by finding periods in which the confidence intervals do not include zero. The advantage of the bootstrapping procedure over other approaches is that this procedure requires few assumptions about the distribution of the statistic of interest, and that we use the observed data to probe the distribution of the statistic. The disadvantage of the bootstrapping procedure is that it is computationally intensive. Here we considered 3,000 resamplings, but we could easily consider more.</p>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> Compare the confidence intervals in the plot above (bootstrap confidence intervals) to <a href="#plt:erpA-m1">the CLT confidence intervals</a> computed earlier. How are the two results similar or different? What happens to the confidence intervals if you change the number of resamplings in step 3 from 3,000 to 10,000?</p>
</div>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> Compute the confidence intervals using the bootstrapping procedure for the ERP of condition B. What do you find?</p>
</div>

<p>+++</p>

<p><a href="#introduction">Return to top</a></p>

<p>+++</p>

<h3 id="a-bootstrap-test-to-compare-erps-">A Bootstrap Test to Compare ERPs <a id="bootstrap"></a>
</h3>

<p>```{code-cell} ipython3
YouTubeVideo(‘K6pgCxFdELc’)</p>
<h1 id="no-code-6">NO CODE</h1>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
The bootstrapping procedure provides a powerful technique to construct confidence intervals for the ERPs using only the observed EEG measurements. We can apply a similar technique to search for significant differences between the ERPs in conditions A and B. To do so, we first choose a *statistic*, a measure of some attribute of the difference between the two ERPs. There are many choices, some informative and some not. Let’s choose as our statistic the maximum absolute value of the difference in the ERPs across time. Computing this statistic is straightforward in Python:

```{code-cell} ipython3
mbA = np.mean(EEGa,0)          # Determine ERP for condition A
mnB = np.mean(EEGb,0)          # Determine ERP for condition B
mnD = mnA - mnB                # Compute the differenced ERP
stat = max(np.abs(mnD))        # Compute the statistic
print('stat = {:.4f}'.format(stat))
</code></pre></div></div>

<div class="question">

  <p><strong>Q.</strong> Given the value we determined for <code class="language-plaintext highlighter-rouge">stat</code>, are the ERPs for the two conditions different?</p>
</div>

<p>```{code-cell} ipython3
YouTubeVideo(‘390ywma7S3U’)</p>
<h1 id="no-code-7">NO CODE</h1>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
In isolation, the numerical value for `stat` is not very useful or interesting. Is the value for `stat` consistent with noisy scalp EEG data lacking an evoked response? Or is the value for `stat` large and unexpected to occur unless the ERPs in the two conditions are different? To make the statistic useful, we need `stat` to be interpretable, which we pursue here through a bootstrapping procedure. We assume that no difference exists between the two conditions; in the language of statistics, this is called the [*null hypothesis*](https://en.wikipedia.org/wiki/Null_hypothesis). If the null hypothesis holds, then we can pool all the EEG signals together from both conditions (for a total of 2,000 trials) and draw from this combined distribution to create resampled ERPs representative of either condition.

It may seem odd to create pseudodata by selecting trials across both conditions; intuitively, we may expect the data to differ in these two conditions and feel uncomfortable making a pseudodata set that includes trials from both conditions. But under the null hypothesis, we assume no difference between the EEG responses in conditions A and B, and we are therefore free to create pseudodata drawing from trials in both conditions. We do so with the goal of creating a distribution of values for `stat` under the null hypothesis that conditions A and B exhibit no difference. We then compare the observed value of `stat` with this distribution of `stat` values. If there is a difference between the two conditions, we expect to find the observed value of `stat` to be very different from the distribution of `stat` values generated from the pseudodata under the null hypothesis.

To create the distribution of `stat` values under the null hypothesis of no difference between the two conditions, we perform a bootstrap test. The idea is similar to the bootstrapping procedure used to construct the [confidence intervals for the ERP](#fig:1)&lt;span class="sup"&gt;fig&lt;img src="imgs/2-1.png"&gt;&lt;/span&gt;. We proceed as follows:

1. Merge the 1,000 trials each of EEG data from conditions A and B to form a combined distribution of 2,000 trials.
1. Sample with replacement 1,000 trials of EEG data from the combined distribution, and compute the resampled ERP.
1. Repeat step 2 and compute a second resampled ERP.
1. Compute the statistic, the maximum absolute value of the difference between the two resampled ERPs.
1. Repeat steps 2-4, 3,000 times to create a distribution of statistic values.
1. Compare the observed statistic to this distribution of statistic values. If the observed statistic is greater than 95% of the bootstrapped values, then reject the null hypothesis that the two conditions are the same.

The code to implement this procedure is similar to the bootstrapping procedure that we have already implemented to compute the confidence intervals for the ERP:

```{code-cell} ipython3
EEG = np.vstack((EEGa, EEGb))  # Step 1. Merge EEG data from all trials
np.random.seed(123)  # For reproducibility

def bootstrapStat(EEG):  # Steps 2-4.
    mnA = bootstrapERP(EEG, size=ntrials)  # Create resampled ERPa. The function 'bootstrapERP' is defined above!
    mnB = bootstrapERP(EEG, size=ntrials)  # Create resampled ERPb
    mnD = mnA - mnB  # Compute differenced ERP
    return max(abs(mnD))  # Return the statistic

statD = [bootstrapStat(EEG) for _ in range(3000)]  # Resample 3,000 times
</code></pre></div></div>

<p>In this code, we first combine <code class="language-plaintext highlighter-rouge">EEGa</code> and <code class="language-plaintext highlighter-rouge">EEGb</code> in a new variable <code class="language-plaintext highlighter-rouge">EEG</code>.
Then, as before, we define the function <code class="language-plaintext highlighter-rouge">bootstrapStat</code> which performs the operations that we wish to repeat. Both of the first two lines of the function call <code class="language-plaintext highlighter-rouge">bootstrapERP</code>, the function that we defined earlier to compute a resampled ERP. Note that in this case, we call <code class="language-plaintext highlighter-rouge">bootstrapERP</code> with <code class="language-plaintext highlighter-rouge">size=ntrials</code>. When we combined the original datasets in <code class="language-plaintext highlighter-rouge">EEG</code>, we generated a dataset with twice the number of trials, but we still wish to perform the bootstrap procedure to create a resampled ERP using the original number of trials (1,000). The last two lines of the function compute the resampled difference and return the statistic. Finally, we repeat the procedure 3,000 times using a for-loop.</p>

<p>```{code-cell} ipython3
YouTubeVideo(‘iefCPGHd5vY’)</p>
<h1 id="no-code-8">NO CODE</h1>
<p>```</p>

<p><img alt="Bootstrap distribution of statistic values" title="" src="imgs/bootstrapERPdiff.png" height="20" width="600"></p>

<p>+++</p>

<p>The figure above shows the distribution of values for the test statistic under the null hypothesis of no difference between the two conditions. The orange line indicates observed statistic from the EEG data.</p>

<p>+++</p>

<div class="python-note">

  <p>The <code class="language-plaintext highlighter-rouge">seed()</code> function controls the random numbers that are generated. This ensures that when you recreate the plot above, yours will look identical. Nonetheless, if you remove (or comment out) this statement, your plot should still look very similar as the distribution should change only slightly.</p>
</div>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> See if you can write code to generate this plot using the <code class="language-plaintext highlighter-rouge">hist()</code> function from the NumPy module.</p>
</div>

<p>+++</p>

<div class="question">

  <p><strong>Q.</strong> Given the distribution of <code class="language-plaintext highlighter-rouge">statD</code> values shown above, and the value of <code class="language-plaintext highlighter-rouge">stat</code> computed from the original data, can we conclude that the difference between the two conditions is significant with this statistic?</p>

  <p><strong>A.</strong> Yes. Under the null hypothesis, the distribution fo the statistic ranges from approximately 0.15 to 0.33. The observed statistic <code class="language-plaintext highlighter-rouge">stat = 0.2884</code> exceeds most values in this distribution. Computing <code class="language-plaintext highlighter-rouge">sum(statD &gt; stat)</code> we find in this example that only 18 of the 3,000 values in the distribution exceed the observed statistic. This corresponds to a proportion of 18/3000 = 0.006. We therefore reject the null hypothesis of no difference between the ERPs of conditions A and B. This result may be surprising, given how similar the two ERPs appear and the large variability in their differences (<a href="#plt:differencedERP">see figure</a>).</p>
</div>

<p>+++</p>

<p>This result illustrates the power of the bootstrapping procedure. We proposed a complicated statistic (the maximum absolute value of the difference between the two resampled ERPs). For this statistic, we do not possess an obvious formula to decide whether the resulting statistic is significant (we cannot rely on the CLT, for example). To determine significance, we employ a bootstrapping procedure (also known as a permutation test), which we can perform even for the relatively complicated statistic. In this way, we may devise complicated measures of data and construct error bars or compute statistical significance, provided our computational resources are sufficient.</p>

<p>+++</p>

<p><a href="#introduction">Return to top</a></p>

<p>+++</p>

<h2 id="summary-">Summary <a id="summary"></a>
</h2>

<p>+++</p>

<p>In this notebook, we considered scalp EEG data recorded from a single electrode during an auditory task. The task consisted of two conditions, and we sought to uncover the difference in the EEG responses between the two conditions. We began with a visual inspection of the EEG recordings from individual trials and from all trials, and concluded that the data were quite noisy; any evoked response due to the stimulus was not obvious in the single-trial data.</p>

<p>To emphasize the evoked signal, we computed the ERP, which involved averaging the EEG signal across trials. By doing so, we uncovered interesting structure in condition A, but not much in condition B. We then developed two techniques to add error bars to an ERP. One technique relied on the central limit theorem, and the other technique involved a computationally expensive bootstrapping procedure. Both techniques suggested that the ERP in condition A differed significantly from zero following the stimulus at time 0.25 s.</p>

<p>Finally, we assessed whether the two ERPs from condition A and condition B differed. We did so through visual inspection, by comparing the differences in the ERPs, and by computing a statistic and assessing its significance through a bootstrapping procedure. Using the last procedure, we concluded that the ERP in the two conditions significantly differed.</p>

<p>+++</p>

<p><a href="#introduction">Return to top</a></p>

            </div>
            <div class="c-textbook__footer" id="textbook_footer">
              
<nav class="c-page__nav">
  

  
</nav>

              <footer>
  <p class="footer">This page was created by <a href="https://github.com/jupyter/jupyter-book/graphs/contributors" target="_blank" rel="noopener noreferrer">The Jupyter Book Community</a></p>
</footer>

            </div>

        </main>
</div>
      
    
  </body>
</html>
